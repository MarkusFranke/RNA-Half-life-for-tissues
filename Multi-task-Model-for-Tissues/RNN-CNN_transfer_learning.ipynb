{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090357d2",
   "metadata": {},
   "source": [
    "This notebook objective is Multi-tissue prediction of mRNA half-life from sequence using transfer learning of Hybird RNN-CNN with Batch Normalization model that was trained on general half-life prediction on Saluki dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573151d-ca56-4c33-8fb1-25f2120410d9",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c54a6-1a59-4175-8935-f3086d504e54",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1658089444704,
     "user": {
      "displayName": "yasmine zakaria",
      "userId": "13545264150180415322"
     },
     "user_tz": -120
    },
    "id": "krhP9y57qL7K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kipoiseq.transforms.functional import one_hot, fixed_len\n",
    "import numpy as np\n",
    "from plotnine import ggplot, aes, geom_histogram\n",
    "\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import keras.layers as kl\n",
    "import keras\n",
    "import numpy as np\n",
    "# we use the kipoiseq package for one hot encoding\n",
    "from kipoiseq.transforms.functional import one_hot, fixed_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91805b7-d1bc-47c7-bcf0-039ebe7da26e",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- Reading Multi-tissue Dataset\n",
    "- one-hot encode of 6 tracks\n",
    "    - (4) RNA sequence (A, G, T, C)\n",
    "    - (1) Exon binding sites\n",
    "    - (1) starts of codons\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427cad0-998c-4fed-b6af-6f848f8b4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset exercise dataset with mean_hl and exons junctions\n",
    "# NaNs for tissues hl were set to -1000.0\n",
    "tissue_hl = pd.read_csv('../data/genomic_sequence_plus_features_hl_all_tissues_with_ss.csv', index_col=0)\n",
    "tissue_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf34f9-a391-43ce-8b77-4b3f8934847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = tissue_hl.columns[1:]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd8ef4-1c9b-46af-a10d-9debc65fd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nans\n",
    "# keep mRNAs with annotated 3' and 5' UTRs\n",
    "tissue_hl = tissue_hl.loc[tissue_hl.loc[:, ['3_utr', '5_utr']].dropna().index]\n",
    "tissue_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3736fb-8790-4fc7-b15a-c33dd8a2be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_hl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565bd38-165e-4760-b6fb-34996a2b796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = tissue_hl['5_utr'] + tissue_hl['cds'] + tissue_hl['3_utr'] #full sequence\n",
    "print(seqs)\n",
    "len_seqs = pd.DataFrame([len(seq) for seq in seqs], columns=['len'])\n",
    "\n",
    "(ggplot(len_seqs, aes('len'))\n",
    "  + geom_histogram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf138cc-3d10-4520-b800-cd382261325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuttoff 10000 nucleotides\n",
    "max_len = 10000\n",
    "def pad_sequence(seqs, max_len, anchor='start', value='N'):\n",
    "  padded_seqs = [fixed_len(seq, max_len, anchor=anchor) for seq in seqs.astype(\"string\")]\n",
    "  return padded_seqs\n",
    "fixed_len_seqs = np.array(pad_sequence(seqs, max_len))\n",
    "del seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9860d5-f69e-4962-89ae-48a8384d803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#track six\n",
    "starts = []\n",
    "\n",
    "for i in range(len(tissue_hl)):\n",
    "  #assert len(sequences['ORF_seqs'].astype(\"string\")[i]) % 3 == 0 \n",
    "    lst = list(range(len(tissue_hl['cds'].astype(\"string\")[i])))\n",
    "    onehot = np.repeat(0, repeats = len(tissue_hl['cds'].astype(\"string\")[i]))\n",
    "\n",
    "    onehot[lst[0::3]] = 1\n",
    "    full = np.concatenate((np.repeat([0], repeats = len(tissue_hl['5_utr'].astype(\"string\")[i])),\n",
    "                         onehot,\n",
    "                         np.repeat([0], repeats = len(tissue_hl['3_utr'].astype(\"string\")[i]))), axis=None)\n",
    "    \n",
    "    if (len(full) > max_len):\n",
    "        full = full[:max_len]\n",
    "    elif (len(full) < max_len):\n",
    "        full = np.concatenate((full, np.repeat(0, repeats = max_len - len(full))),axis = None)\n",
    "    starts.append(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349aaed-2170-43c4-afc3-2c7f88e19be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot for track 5: the exon binding sites\n",
    "exons = []\n",
    "\n",
    "for i in range(len(tissue_hl)):\n",
    "  onehot = np.repeat(0, repeats = max_len)\n",
    "  if(isinstance(tissue_hl[\"Exon_Junctions\"][i], str)):\n",
    "    current_exons = list(map(int, tissue_hl[\"Exon_Junctions\"][i].split(\";\")))\n",
    "    assert len(current_exons) > 0\n",
    "    positions_capped = [x for x in current_exons if x <= 10000] # delete all exon junctions after 10000 since we're capping the sequence there\n",
    "    onehot[positions_capped] = 1\n",
    "  exons.append(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab9d27-5b87-4292-be82-e23cd9afffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_seqs = np.array([one_hot(seq, neutral_value=0) for seq in fixed_len_seqs])\n",
    "seqs = np.stack([one_hot_seqs[:,:,0], one_hot_seqs[:,:,1], one_hot_seqs[:,:,2], one_hot_seqs[:,:,3],\n",
    "                 np.array(exons), np.array(starts)], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06663a3-d2d5-4d6c-bdad-e1b7ed8ccf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9dc9b0-1d3c-4658-83e7-6cfe7b8c2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "del [starts, full, len_seqs, one_hot_seqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c80782-3acb-4f2f-8972-bdf72f673928",
   "metadata": {},
   "source": [
    "## Prepare dataset for training\n",
    "split according to chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b788b-5fc1-423f-833b-a47799e0a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_val = ['chr2', 'chr3', 'chr4']\n",
    "chrom_test = ['chr1', 'chr8', 'chr9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a9ad1-79b8-41a2-9269-0678fd66d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = np.where(tissue_hl.chromosome.isin(chrom_test))[0]\n",
    "idx_val = np.where(tissue_hl.chromosome.isin(chrom_val))[0]\n",
    "idx_train = np.where(~(tissue_hl.chromosome.isin(chrom_test)| tissue_hl.chromosome.isin(chrom_val)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c7cb7-e31e-4fc9-8395-6daee691639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(array, idx_train, idx_val, idx_test):\n",
    "  return array[idx_train], array[idx_val], array[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f72475-222d-41bb-9f07-897af1cf0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues = tissue_hl.columns[1:50]\n",
    "tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc0a9d-c188-4f0a-b0ad-95a8c7f44efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f937a7-100f-4122-b18c-173946177cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask nans with -1000\n",
    "mask_value = -1000\n",
    "tissue_hl.loc[:, tissues] = tissue_hl.loc[:, tissues].fillna(mask_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bff78-a481-4a89-897e-4bfcd8452b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = train_test_split(seqs, idx_train, idx_val, idx_test)\n",
    "y_vars = list(tissues)\n",
    "y_train, y_val, y_test = train_test_split(tissue_hl.loc[:, y_vars].values, idx_train, idx_val, idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533060b-86b9-4733-a742-fe0e01de59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e076675-f68f-47cb-be91-140a2256c1d1",
   "metadata": {},
   "source": [
    "## Training the multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497617e6-fd78-4902-9762-aaea6101d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Hybird CNN-RNN with Batch Normalization model that was trained on Saluki dataset\n",
    "model = keras.models.load_model('../data/Models for transfer learning/my_saluki5_23_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9eb49-834b-4e11-8493-ad7fe94cfc5a",
   "metadata": {},
   "source": [
    "### Model transfer and last layers change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63007fa-403b-4317-a1b8-d99faa67a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new model by using part of the model constructed previously by keeping all layers but the last one.\n",
    "\n",
    "transferred_model = Model(model.inputs, model.layers[-2].output)\n",
    "\n",
    "transferred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a401f-9165-4645-adca-438dc5cef0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "for layer in transferred_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a7e51-3ee9-4625-b805-05a0467456fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-task model by using the transferred layers plus extra layers for the prediction on each task\n",
    "\n",
    "input = kl.Input(X_train.shape[1:])\n",
    "x = transferred_model(input)\n",
    "\n",
    "x = kl.Dense(units = 128, kernel_regularizer=tf.keras.regularizers.l2(l=0.0015))(x)\n",
    "x = kl.Dense(units = 128, kernel_regularizer=tf.keras.regularizers.l2(l=0.0015))(x)\n",
    "x = tfa.layers.GELU()(x)\n",
    "print(x.shape)\n",
    "\n",
    "output = kl.Dense(units=len(tissues))(x)\n",
    "mt_model_transfer = Model(inputs=input, outputs=output)\n",
    "# mt_model_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af6829-6c28-4b88-b175-8adc39f5d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss functions to handle NaNs\n",
    "from keras import backend as K\n",
    "mask_value = -1000\n",
    "def function_masked_mse(y_true, y_pred):\n",
    "        mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "        masked_summed_error = K.sum(K.square(mask * (y_true - y_pred)), axis=1)\n",
    "        smooth=0\n",
    "        masked_mean_squared_error = masked_summed_error / (K.sum(mask, axis=1) + smooth)\n",
    "\n",
    "        return masked_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a9ad6-fb47-4975-a475-2876f5a38ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now compile the model using our custom loss function: function_masked_mse, use lw lr\n",
    "mt_model_transfer.compile(optimizer=keras.optimizers.Adam(lr = 0.0001), loss=function_masked_mse)\n",
    "\n",
    "# Train the model\n",
    "history_transfer = mt_model_transfer.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[EarlyStopping(patience=15, restore_best_weights=True),\n",
    "                              ],\n",
    "                    batch_size=32,  \n",
    "                    epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16de06b-c7e7-47f0-9621-9d7a165fbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to plot val and train losses\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(history):\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    ax.plot(history['loss'][1:], label=\"train_loss\")\n",
    "    ax.plot(history['val_loss'][1:], label=\"val_loss\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.ylabel('mean squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06a12b-4d4a-4654-8b49-7e015990b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_transfer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6168a79-8e7a-4b32-90dc-2e10b4902b8c",
   "metadata": {},
   "source": [
    "### Unfreeze some layers and re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789811d-23aa-4bdb-bd93-d1fd1bd8c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model_transfer.get_layer('model').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2a0fc-f952-4fe4-991f-dad2778b8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last dense layer\n",
    "mt_model_transfer.get_layer('model').get_layer('dense').trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acf14a-9b91-4448-a650-4ff881e63fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model_transfer.compile(optimizer=keras.optimizers.Adam(lr = 0.0001), loss=function_masked_mse)\n",
    "\n",
    "# Train the model\n",
    "history_transfer = mt_model_transfer.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[EarlyStopping(patience=15, restore_best_weights=True),\n",
    "                    ],\n",
    "                    batch_size=32,  \n",
    "                    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ffd38-ff5a-49ca-a449-93180c70a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_transfer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4911e0-1b61-47f2-b3a1-dc689b4a12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "mt_model_transfer.save(\"model_exp_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696a251-b5c7-4c4e-aa17-397dbbd88d54",
   "metadata": {},
   "source": [
    "Now let's evaluate the final model on each task/tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f8310-d01e-4873-b3be-e8cdd324a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_transfer_val = mt_model_transfer.predict(X_val)\n",
    "\n",
    "preds_transfer_val_df = pd.DataFrame(preds_transfer_val, columns=y_vars, \n",
    "                                     index=tissue_hl.iloc[idx_val].index)\n",
    "\n",
    "true_val_df = tissue_hl.iloc[idx_val].loc[:, y_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2675c-4fe2-4593-99db-ebfbf38955e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "# This function inputs 2 dataframes with tasks as columns and \n",
    "# mRNAs as rows. One data frame contains the true (measured) values\n",
    "# and the other the predicted ones.\n",
    "# The output is a dataframe with \n",
    "# 2 columns: task and explained variance score\n",
    "\n",
    "def get_scores(true_df, pred_df):\n",
    "\n",
    "  exp_var_scores = []\n",
    "  r2_scores = []\n",
    "\n",
    "  for y_var in y_vars:\n",
    "    non_na_idxs = true_df[true_df[y_var]!= mask_value].index\n",
    "    exp_var_scores.append(explained_variance_score(true_df.loc[non_na_idxs, y_var].values, pred_df.loc[non_na_idxs, y_var].values))\n",
    "    r2_scores.append(r2_score(true_df.loc[non_na_idxs, y_var].values, pred_df.loc[non_na_idxs, y_var].values))\n",
    "  scores_df = pd.DataFrame({'task':y_vars, 'exp_var_score': exp_var_scores, \"r2_score\": r2_scores})\n",
    "\n",
    "  return scores_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb5106-992d-451c-adec-2f239814ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scores\n",
    "val_transfer_scores_df = get_scores(true_val_df, preds_transfer_val_df)\n",
    "\n",
    "# Plot scores per task\n",
    "fig = p9.ggplot(val_transfer_scores_df, p9.aes('task', 'exp_var_score')) + p9.geom_col() + p9.theme(axis_text_x = p9.element_text(angle = 90))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321010a-2bbc-4475-8ad0-c0a478ae1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_score = explained_variance_score(true_val_df, preds_transfer_val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72c870-5512-4bf1-b9ba-38d51f95aa76",
   "metadata": {},
   "source": [
    "### Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48bab76-49a2-435b-a829-eec8439a2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_transfer_test = mt_model_transfer.predict(X_test)\n",
    "preds_transfer_test_df = pd.DataFrame(preds_transfer_test, columns=y_vars, \n",
    "                                     index=tissue_hl.iloc[idx_test].index)\n",
    "\n",
    "true_test_df = tissue_hl.iloc[idx_test].loc[:, y_vars]\n",
    "# Get the scores\n",
    "test_transfer_scores_df = get_scores(true_test_df, preds_transfer_test_df)\n",
    "\n",
    "# Plot scores per task\n",
    "p9.ggplot(test_transfer_scores_df, p9.aes('task', 'exp_var_score')) + p9.geom_col() + p9.theme(axis_text_x = p9.element_text(angle = 90))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd52f30-a4ee-44aa-9e09-30ef2ac65119",
   "metadata": {},
   "source": [
    "### All layers are trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffdc4d-ba27-4a50-9dbe-52ec5202df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in transferred_model.layers:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94d423-f63d-4bb2-8d6f-3a71674255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now create the multi-task model by using the transferred layers plus extra layers for the prediction on each task\n",
    "\n",
    "input = kl.Input(X_train.shape[1:])\n",
    "x = transferred_model(input)\n",
    "\n",
    "\n",
    "\n",
    "x = kl.Dense(units = 128)(x)\n",
    "x = kl.Dense(units = 128)(x)\n",
    "x = tfa.layers.GELU()(x)\n",
    "output = kl.Dense(units=len(tissues))(x)\n",
    "mt_model_transfer_scratch = Model(inputs=input, outputs=output)\n",
    "# mt_model_transfer_scratch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf700e9-13fe-4a18-8b44-083ebcd60de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now compile the model using our custom loss function: function_masked_mse\n",
    "mt_model_transfer_scratch.compile(optimizer=keras.optimizers.Adam(lr = 0.0001), loss=function_masked_mse)\n",
    "\n",
    "# Train the model\n",
    "history_transfer_scratch = mt_model_transfer_scratch.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[EarlyStopping(patience=15, restore_best_weights=True),\n",
    "                    ],\n",
    "                    batch_size=32,  \n",
    "                    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239a3c5-79ec-49ff-8cd8-985a48f1c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history_transfer_scratch.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de2ca3-3d19-46c1-b87e-6df40043c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "mt_model_transfer_scratch.save(\"model_exp_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50326f7b-8768-40d9-8bd5-1a6e629b5f44",
   "metadata": {},
   "source": [
    "#### Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13db6af-1d76-4e68-9ad7-c307e608d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test in val data\n",
    "preds_transfer_val = mt_model_transfer_scratch.predict(X_val)\n",
    "\n",
    "preds_transfer_val_df = pd.DataFrame(preds_transfer_val, columns=y_vars, \n",
    "                                     index=tissue_hl.iloc[idx_val].index)\n",
    "\n",
    "true_val_df = tissue_hl.iloc[idx_val].loc[:, y_vars]\n",
    "# Get the scores\n",
    "val_transfer_scores_df = get_scores(true_val_df, preds_transfer_val_df)\n",
    "\n",
    "# Plot scores per task\n",
    "fig = p9.ggplot(val_transfer_scores_df, p9.aes('task', 'exp_var_score')) + p9.geom_col() + p9.theme(axis_text_x = p9.element_text(angle = 90))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddc126-d5bf-4adb-b2f8-4e54a2bdbf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test in val data\n",
    "preds_transfer_test = mt_model_transfer_scratch.predict(X_test)\n",
    "preds_transfer_test_df = pd.DataFrame(preds_transfer_test, columns=y_vars, \n",
    "                                     index=tissue_hl.iloc[idx_test].index)\n",
    "\n",
    "true_test_df = tissue_hl.iloc[idx_test].loc[:, y_vars]\n",
    "# Get the scores\n",
    "test_transfer_scores_df = get_scores(true_test_df, preds_transfer_test_df)\n",
    "\n",
    "# Plot scores per task\n",
    "fig = p9.ggplot(test_transfer_scores_df, p9.aes('task', 'exp_var_score')) + p9.geom_col() + p9.theme(axis_text_x = p9.element_text(angle = 90))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008ac03",
   "metadata": {},
   "source": [
    "#### Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcf08d-856a-4318-9291-dd453934a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained-variance score stats across tissues\n",
    "print(\"min: \", test_transfer_scores_df[\"exp_var_score\"].min())\n",
    "print(\"max: \", test_transfer_scores_df[\"exp_var_score\"].max())\n",
    "print(\"mean: \", test_transfer_scores_df[\"exp_var_score\"].mean())\n",
    "print(\"median: \", test_transfer_scores_df[\"exp_var_score\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ca269-fc9a-4a07-8e9b-e9d026dbf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tissues with top 4 explained-variance\n",
    "test_transfer_scores_df.sort_values([\"exp_var_score\"], ascending=False)[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
