{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saluki v26 - LayerNorm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusFranke/RNA-Half-life-for-tissues/blob/main/models-for-general-half-life/Saluki_v26_LayerNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKkQxNHexGtb"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO #for parsing Fasta Files\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from kipoiseq.transforms.functional import one_hot, fixed_len\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as k\n",
        "from keras.callbacks import EarlyStopping, History\n",
        "from keras.models import Model\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import keras.layers as kl\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can't run this in google colab due to RAM limitations, I'm importing the data from disk. All the data should be available on google drive though, under the same filenames, either to be downloaded and run with a path to where the user saved them, or to be directly accessible by mounting the google drive (and setting a shortcut to our google drive data path in google drive)\n"
      ],
      "metadata": {
        "id": "ku26rqE7x06J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hl = pd.read_excel(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\kelley_et_al_corrected_hl.xlsx', skiprows=[0, 1])\n",
        "hl['zscore'] = zscore(hl['half-life (PC1)'])\n",
        "halflife = hl[[\"Ensembl Gene Id\", \"zscore\"]]\n",
        "hl"
      ],
      "metadata": {
        "id": "7vRfq7bIxy4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "474befdb-e51b-49c6-c86f-48236f1c38e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ensembl Gene Id  Gene name  half-life (PC1)  Bazzini_ActD_HEK293_1  \\\n",
              "0      ENSG00000000003     TSPAN6         8.660955               0.763166   \n",
              "1      ENSG00000000419       DPM1         2.241221               0.529938   \n",
              "2      ENSG00000000457      SCYL3        -6.929173              -0.798471   \n",
              "3      ENSG00000000460   C1orf112         0.440909               0.461228   \n",
              "4      ENSG00000000938        FGR        -0.943680               0.164310   \n",
              "...                ...        ...              ...                    ...   \n",
              "13916  ENSG00000284770       TBCE         2.218664               0.100281   \n",
              "13917  ENSG00000285077  ARHGAP11B        -3.262964              -0.733980   \n",
              "13918  ENSG00000288596    C8orf44         2.118850              -0.485957   \n",
              "13919  ENSG00000288701     PRRC2B         0.133147               0.133770   \n",
              "13920  ENSG00000288722       F8A1        -3.485607              -0.607463   \n",
              "\n",
              "       Bazzini_ActD_HeLa_1  Bazzini_ActD_RPE_1  Bazzini_4sU_K562_1  \\\n",
              "0                 0.258448            0.106486            1.019072   \n",
              "1                 0.222678           -0.040666           -0.284952   \n",
              "2                -0.894854           -1.039150           -1.444532   \n",
              "3                 0.195794           -0.739672           -0.123925   \n",
              "4                 0.112064            0.095773            0.045345   \n",
              "...                    ...                 ...                 ...   \n",
              "13916            -0.187624           -0.143422            0.201024   \n",
              "13917            -0.934478           -0.952570           -0.461339   \n",
              "13918            -0.320560           -0.332189            0.582473   \n",
              "13919             0.214899            0.144491            0.090991   \n",
              "13920            -0.419258           -0.378650           -0.775774   \n",
              "\n",
              "       Akimitsu_BrU_HeLa_1  Rinn_ActD_K562_1  Rinn_ActD_K562_2  ...  \\\n",
              "0                 2.022504          1.744745          1.783356  ...   \n",
              "1                 0.145097          0.866919          0.832768  ...   \n",
              "2                -1.287191         -1.006317         -1.062201  ...   \n",
              "3                 0.162538         -0.023056         -0.008479  ...   \n",
              "4                 0.024136         -0.209157         -0.223700  ...   \n",
              "...                    ...               ...               ...  ...   \n",
              "13916             0.933352          0.465403          0.451758  ...   \n",
              "13917            -0.940048          0.225157          0.161858  ...   \n",
              "13918            -0.614775          0.305297          0.336730  ...   \n",
              "13919             0.131956         -0.040831         -0.035576  ...   \n",
              "13920             0.400149         -1.060379         -1.033201  ...   \n",
              "\n",
              "       Gejman_4sU_GM12812_1  Gejman_4sU_GM12814_1  Gejman_4sU_GM12815_1  \\\n",
              "0                  1.037361              0.969166              1.209562   \n",
              "1                 -0.212424             -0.747989              0.371214   \n",
              "2                 -1.155096             -1.421651             -1.568912   \n",
              "3                  1.365208              1.017193             -0.239569   \n",
              "4                  0.722198              1.024313              1.484018   \n",
              "...                     ...                   ...                   ...   \n",
              "13916              1.082013              0.917651              0.897480   \n",
              "13917              0.256969              0.033071             -0.249782   \n",
              "13918              1.023526             -0.155662             -0.950892   \n",
              "13919             -0.091563             -0.021327             -0.017414   \n",
              "13920              0.433892              0.446224              1.344124   \n",
              "\n",
              "       Simon_4sU_K562_1  Simon_4sU_K562_2  Rissland_4sU_HEK293_1  \\\n",
              "0              2.080643          2.095154               0.674058   \n",
              "1              0.772595          0.712843              -0.350914   \n",
              "2             -1.308978         -1.311572              -0.387172   \n",
              "3              0.373929          0.380154              -0.063720   \n",
              "4             -0.375671         -0.384504               0.232924   \n",
              "...                 ...               ...                    ...   \n",
              "13916          0.866792          0.868080              -0.104068   \n",
              "13917         -1.116405         -1.078302              -1.495412   \n",
              "13918         -0.175193         -0.166760               2.505294   \n",
              "13919          0.088581          0.107441               0.345123   \n",
              "13920         -0.631782         -0.629741              -0.413725   \n",
              "\n",
              "       Rissland_4sU_HEK293_2  Rissland_4sU_HEK293_3  Rissland_4sU_HEK293_4  \\\n",
              "0                   1.120375               1.456258               1.791769   \n",
              "1                  -0.879247              -0.825603               0.109861   \n",
              "2                  -1.229226              -1.122749              -0.570002   \n",
              "3                  -0.450610              -0.805719               0.453957   \n",
              "4                   0.347933               0.266619               0.063565   \n",
              "...                      ...                    ...                    ...   \n",
              "13916              -0.169414              -0.404886              -0.165188   \n",
              "13917              -1.006317              -1.240272              -1.440629   \n",
              "13918               1.068162               1.307039               1.563308   \n",
              "13919              -0.188176              -0.119128               0.001050   \n",
              "13920              -0.071227              -0.105036              -0.197549   \n",
              "\n",
              "         zscore  \n",
              "0      1.807620  \n",
              "1      0.467763  \n",
              "2     -1.446182  \n",
              "3      0.092022  \n",
              "4     -0.196955  \n",
              "...         ...  \n",
              "13916  0.463055  \n",
              "13917 -0.681011  \n",
              "13918  0.442223  \n",
              "13919  0.027789  \n",
              "13920 -0.727478  \n",
              "\n",
              "[13921 rows x 58 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ensembl Gene Id</th>\n",
              "      <th>Gene name</th>\n",
              "      <th>half-life (PC1)</th>\n",
              "      <th>Bazzini_ActD_HEK293_1</th>\n",
              "      <th>Bazzini_ActD_HeLa_1</th>\n",
              "      <th>Bazzini_ActD_RPE_1</th>\n",
              "      <th>Bazzini_4sU_K562_1</th>\n",
              "      <th>Akimitsu_BrU_HeLa_1</th>\n",
              "      <th>Rinn_ActD_K562_1</th>\n",
              "      <th>Rinn_ActD_K562_2</th>\n",
              "      <th>...</th>\n",
              "      <th>Gejman_4sU_GM12812_1</th>\n",
              "      <th>Gejman_4sU_GM12814_1</th>\n",
              "      <th>Gejman_4sU_GM12815_1</th>\n",
              "      <th>Simon_4sU_K562_1</th>\n",
              "      <th>Simon_4sU_K562_2</th>\n",
              "      <th>Rissland_4sU_HEK293_1</th>\n",
              "      <th>Rissland_4sU_HEK293_2</th>\n",
              "      <th>Rissland_4sU_HEK293_3</th>\n",
              "      <th>Rissland_4sU_HEK293_4</th>\n",
              "      <th>zscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>TSPAN6</td>\n",
              "      <td>8.660955</td>\n",
              "      <td>0.763166</td>\n",
              "      <td>0.258448</td>\n",
              "      <td>0.106486</td>\n",
              "      <td>1.019072</td>\n",
              "      <td>2.022504</td>\n",
              "      <td>1.744745</td>\n",
              "      <td>1.783356</td>\n",
              "      <td>...</td>\n",
              "      <td>1.037361</td>\n",
              "      <td>0.969166</td>\n",
              "      <td>1.209562</td>\n",
              "      <td>2.080643</td>\n",
              "      <td>2.095154</td>\n",
              "      <td>0.674058</td>\n",
              "      <td>1.120375</td>\n",
              "      <td>1.456258</td>\n",
              "      <td>1.791769</td>\n",
              "      <td>1.807620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000419</td>\n",
              "      <td>DPM1</td>\n",
              "      <td>2.241221</td>\n",
              "      <td>0.529938</td>\n",
              "      <td>0.222678</td>\n",
              "      <td>-0.040666</td>\n",
              "      <td>-0.284952</td>\n",
              "      <td>0.145097</td>\n",
              "      <td>0.866919</td>\n",
              "      <td>0.832768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.212424</td>\n",
              "      <td>-0.747989</td>\n",
              "      <td>0.371214</td>\n",
              "      <td>0.772595</td>\n",
              "      <td>0.712843</td>\n",
              "      <td>-0.350914</td>\n",
              "      <td>-0.879247</td>\n",
              "      <td>-0.825603</td>\n",
              "      <td>0.109861</td>\n",
              "      <td>0.467763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>SCYL3</td>\n",
              "      <td>-6.929173</td>\n",
              "      <td>-0.798471</td>\n",
              "      <td>-0.894854</td>\n",
              "      <td>-1.039150</td>\n",
              "      <td>-1.444532</td>\n",
              "      <td>-1.287191</td>\n",
              "      <td>-1.006317</td>\n",
              "      <td>-1.062201</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.155096</td>\n",
              "      <td>-1.421651</td>\n",
              "      <td>-1.568912</td>\n",
              "      <td>-1.308978</td>\n",
              "      <td>-1.311572</td>\n",
              "      <td>-0.387172</td>\n",
              "      <td>-1.229226</td>\n",
              "      <td>-1.122749</td>\n",
              "      <td>-0.570002</td>\n",
              "      <td>-1.446182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>C1orf112</td>\n",
              "      <td>0.440909</td>\n",
              "      <td>0.461228</td>\n",
              "      <td>0.195794</td>\n",
              "      <td>-0.739672</td>\n",
              "      <td>-0.123925</td>\n",
              "      <td>0.162538</td>\n",
              "      <td>-0.023056</td>\n",
              "      <td>-0.008479</td>\n",
              "      <td>...</td>\n",
              "      <td>1.365208</td>\n",
              "      <td>1.017193</td>\n",
              "      <td>-0.239569</td>\n",
              "      <td>0.373929</td>\n",
              "      <td>0.380154</td>\n",
              "      <td>-0.063720</td>\n",
              "      <td>-0.450610</td>\n",
              "      <td>-0.805719</td>\n",
              "      <td>0.453957</td>\n",
              "      <td>0.092022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>FGR</td>\n",
              "      <td>-0.943680</td>\n",
              "      <td>0.164310</td>\n",
              "      <td>0.112064</td>\n",
              "      <td>0.095773</td>\n",
              "      <td>0.045345</td>\n",
              "      <td>0.024136</td>\n",
              "      <td>-0.209157</td>\n",
              "      <td>-0.223700</td>\n",
              "      <td>...</td>\n",
              "      <td>0.722198</td>\n",
              "      <td>1.024313</td>\n",
              "      <td>1.484018</td>\n",
              "      <td>-0.375671</td>\n",
              "      <td>-0.384504</td>\n",
              "      <td>0.232924</td>\n",
              "      <td>0.347933</td>\n",
              "      <td>0.266619</td>\n",
              "      <td>0.063565</td>\n",
              "      <td>-0.196955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13916</th>\n",
              "      <td>ENSG00000284770</td>\n",
              "      <td>TBCE</td>\n",
              "      <td>2.218664</td>\n",
              "      <td>0.100281</td>\n",
              "      <td>-0.187624</td>\n",
              "      <td>-0.143422</td>\n",
              "      <td>0.201024</td>\n",
              "      <td>0.933352</td>\n",
              "      <td>0.465403</td>\n",
              "      <td>0.451758</td>\n",
              "      <td>...</td>\n",
              "      <td>1.082013</td>\n",
              "      <td>0.917651</td>\n",
              "      <td>0.897480</td>\n",
              "      <td>0.866792</td>\n",
              "      <td>0.868080</td>\n",
              "      <td>-0.104068</td>\n",
              "      <td>-0.169414</td>\n",
              "      <td>-0.404886</td>\n",
              "      <td>-0.165188</td>\n",
              "      <td>0.463055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13917</th>\n",
              "      <td>ENSG00000285077</td>\n",
              "      <td>ARHGAP11B</td>\n",
              "      <td>-3.262964</td>\n",
              "      <td>-0.733980</td>\n",
              "      <td>-0.934478</td>\n",
              "      <td>-0.952570</td>\n",
              "      <td>-0.461339</td>\n",
              "      <td>-0.940048</td>\n",
              "      <td>0.225157</td>\n",
              "      <td>0.161858</td>\n",
              "      <td>...</td>\n",
              "      <td>0.256969</td>\n",
              "      <td>0.033071</td>\n",
              "      <td>-0.249782</td>\n",
              "      <td>-1.116405</td>\n",
              "      <td>-1.078302</td>\n",
              "      <td>-1.495412</td>\n",
              "      <td>-1.006317</td>\n",
              "      <td>-1.240272</td>\n",
              "      <td>-1.440629</td>\n",
              "      <td>-0.681011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13918</th>\n",
              "      <td>ENSG00000288596</td>\n",
              "      <td>C8orf44</td>\n",
              "      <td>2.118850</td>\n",
              "      <td>-0.485957</td>\n",
              "      <td>-0.320560</td>\n",
              "      <td>-0.332189</td>\n",
              "      <td>0.582473</td>\n",
              "      <td>-0.614775</td>\n",
              "      <td>0.305297</td>\n",
              "      <td>0.336730</td>\n",
              "      <td>...</td>\n",
              "      <td>1.023526</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-0.950892</td>\n",
              "      <td>-0.175193</td>\n",
              "      <td>-0.166760</td>\n",
              "      <td>2.505294</td>\n",
              "      <td>1.068162</td>\n",
              "      <td>1.307039</td>\n",
              "      <td>1.563308</td>\n",
              "      <td>0.442223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13919</th>\n",
              "      <td>ENSG00000288701</td>\n",
              "      <td>PRRC2B</td>\n",
              "      <td>0.133147</td>\n",
              "      <td>0.133770</td>\n",
              "      <td>0.214899</td>\n",
              "      <td>0.144491</td>\n",
              "      <td>0.090991</td>\n",
              "      <td>0.131956</td>\n",
              "      <td>-0.040831</td>\n",
              "      <td>-0.035576</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.091563</td>\n",
              "      <td>-0.021327</td>\n",
              "      <td>-0.017414</td>\n",
              "      <td>0.088581</td>\n",
              "      <td>0.107441</td>\n",
              "      <td>0.345123</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.119128</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.027789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13920</th>\n",
              "      <td>ENSG00000288722</td>\n",
              "      <td>F8A1</td>\n",
              "      <td>-3.485607</td>\n",
              "      <td>-0.607463</td>\n",
              "      <td>-0.419258</td>\n",
              "      <td>-0.378650</td>\n",
              "      <td>-0.775774</td>\n",
              "      <td>0.400149</td>\n",
              "      <td>-1.060379</td>\n",
              "      <td>-1.033201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.433892</td>\n",
              "      <td>0.446224</td>\n",
              "      <td>1.344124</td>\n",
              "      <td>-0.631782</td>\n",
              "      <td>-0.629741</td>\n",
              "      <td>-0.413725</td>\n",
              "      <td>-0.071227</td>\n",
              "      <td>-0.105036</td>\n",
              "      <td>-0.197549</td>\n",
              "      <td>-0.727478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13921 rows × 58 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.3pUTRs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    UTR3_identifiers = []\n",
        "    UTR3_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        UTR3_identifiers.append(seq_record.id)\n",
        "        UTR3_seqs.append(seq_record.seq)\n",
        "\n",
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.5pUTRs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    UTR5_identifiers = []\n",
        "    UTR5_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        UTR5_identifiers.append(seq_record.id)\n",
        "        UTR5_seqs.append(seq_record.seq)\n",
        "\n",
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.ORFs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    ORF_identifiers = []\n",
        "    ORF_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        ORF_identifiers.append(seq_record.id)\n",
        "        ORF_seqs.append(seq_record.seq)\n",
        "\n",
        "print(UTR3_seqs[0])\n",
        "print(UTR5_seqs[0])\n",
        "print(ORF_seqs[0])\n",
        "print(UTR3_identifiers[0])\n",
        "print(UTR5_identifiers[0])\n",
        "print(ORF_identifiers[0])\n",
        "print(len(UTR3_seqs))\n",
        "print(len(UTR5_seqs))\n",
        "print(len(ORF_seqs))"
      ],
      "metadata": {
        "id": "JFU1gCykz-M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8412e45-118d-4e35-9c48-3906d81373b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AATATTATGTATGCAGCAATATTTGAGTAACAAGAAGCAAATATCCAAGTTCCAAAATTATAAAAGAAATTCTTATCCAAATAGTAATGTTCTAATTGATCATATAAGAAAGCAAAGCATAGACATTAGAATTATAAGTCAGCAGTGGTCTGTTCAAGAACAATCAACATTTTTAGAAAATAGTAGGACAAAATTAGGAAATAATTATCACCAAGAGGATCTAGTTCATGACTTTCTATTATCTCAATTAGATTGCTCAATCATCAGCCTTCCTATACTAAACTCTGATTCAGGACCAAGAAAGGCATAGTCTGACTCTGGAAATGCGCTGTTGGAAGCCAAATAACATCAATACTCTTGTTCTATAATTGAATATCAAATAAGACAAATTACCATTAATTTAATGACTGTGGAGTTAATTGTATACCAGCATTTCAGCAAATCATCATCAATAGTATTACATTAGCAATTTATGCAATTAAAAGGGCTTTGTAAAACTTTGAATAGATTTTATTGTCATTAGTAGCTGTTGGAACTTCATTATTATATAATGTTTTTGCAAACTTTAACTTTTTTCTAAATTGTTAAATAAAAGAATAACTATCCTTAATCTAAATAATTTTGGTAGCAAATCCTATAAGGTATTAAACATTTTAAGGTATATTATTACATTGCTATTTTACTGTTTCTCATTAACCCAAACAGTTTAAAGGCAGAATTCCACTTAGAAACAAGTTGCATTTTGAAAGTTTATTTGTAATCCATTTGTTTGGAATTCAGAAATGTATTTCACATAAAAATAATCTTGGAAGTAATAAATTCCAAAATTAACTAACAAAA\n",
            "AGATGAGATTTCATCATGTTGGCCAGCCTGGTCTCAAACTCCTGACCTCAAGTGACCCGCCTGCCTCAGCCTCCCAAAGTGCTGGGATTACAGGAATTTAGTGATTGACA\n",
            "ATGGCAGAAAAAATCCTAGAGAAGTTGGATGTCCTTGATAAGCAAGCAGAGATAATCTTGGCCAGAAGAACAAAGATAAACAGGCTTCAGAGTGAAGGAAGAAAAACAACTATGGCTATACCCCTGACATTTGATTTTCAGTTGGAATTTGAAGAAGCTCTTGCTACATCCGCGTCTAAGGCAATATCAAAGATCAAAGAAGACAAGTCATGCAGCATTACAAAATCAAAAATGCATGTCTCTTTCAAATGTGAGCCTGAACCTAGAAAGAGTAATTTTGAAAAGTCAAATTTAAGACCATTCTTTATTCAAACAAATGTAAAAAATAAAGAAAGTGAGTCAACAGCTCAAATTGAAAAAAAACCTAGGAAACCATTGGATTCTGTTGGTCTCTTAGAAGGTGATAGAAATAAAAGAAAAAAATCTCCACAGATGAACGATTTTAATATAAAAGAAAACAAATCGGTCAGAAATTATCAATTAAGTAAGTATAGGTCAGTAAGAAAGAAAAGCTTGCTCCCGTTGTGCTTTGAGGATGAATTGAAAAATCCACATGCCAAGATAGTCAACGTTAGTCCAACAAAGACAGTAACTTCTCACATGGAACAAAAGGACACAAATCCCATAATTTTCCATGACACAGAATATGTACGAATGTTACTTTTGACAAAAAATAGATTTTCTTCTCATCCTTTGGAAAATGAAAACATTTACCCACATAAAAGAACAAATTTCATTTTAGAAAGAAATTGTGAAATCCTCAAATCTATAATTGGCAATCAATCTATTTCTCTTTTCAAACCCCAAAAAACTATGCCTACAGTACAGAGAAAAGATATACAGATCCCTATGTCTTTTAAAGCGGGCCACACAACTGTAGATGATAAACTAAAGAAGAAAACTAATAAGCAGACACTAGAAAACAGATCTTGGAATACACTCTATAATTTCTCACAGAATTTTTCTAGCCTAACAAAACAATTTGTGGGTTACCTTGATAAAGCTGTTATTCATGAAATGAGTGCCCAAACTGGAAAATTTGAAAGAATGTTTTCTGCAGGAAAACCAACGAGCATACCCACATCCAGTGCCTTACCTGTCAAATGTTACTCAAAGCCTTTTAAATATATATATGAACTAAATAATGTAACGCCACTGGATAATTTGTTAAACTTATCAAATGAAATTTTAAATGCCTCA\n",
            "ENSG00000203963\n",
            "ENSG00000203963\n",
            "ENSG00000203963\n",
            "19094\n",
            "18642\n",
            "20253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exons = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Kelley_et_al_exon_junctions.txt', delimiter = \"\\t\")\n",
        "exons"
      ],
      "metadata": {
        "id": "HrhPuo0w0di6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ed5ed5dc-50f3-4d03-a564-70f579f2e416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                GeneID  UTR5_len  \\\n",
              "0      ENSG00000000003       112   \n",
              "1      ENSG00000000457       222   \n",
              "2      ENSG00000000460       700   \n",
              "3      ENSG00000000938       289   \n",
              "4      ENSG00000000971       240   \n",
              "...                ...       ...   \n",
              "13225  ENSG00000278615        48   \n",
              "13226  ENSG00000278619       239   \n",
              "13227  ENSG00000278845       161   \n",
              "13228  ENSG00000280789       574   \n",
              "13229  ENSG00000281991       330   \n",
              "\n",
              "                         Exon_Junctions_In_Full_Sequence  \n",
              "0                                199,388,463,562,697,781  \n",
              "1      387,573,687,744,847,959,1037,1177,1362,1534,16...  \n",
              "2      766,871,1012,1178,1263,1402,1483,1548,1697,182...  \n",
              "3           515,618,717,821,971,1127,1307,1384,1538,1670  \n",
              "4      298,484,590,667,859,1030,1204,1399,1576,1759,1...  \n",
              "...                                                  ...  \n",
              "13225                                         87,212,310  \n",
              "13226                                  781,875,1008,1128  \n",
              "13227                        227,405,523,622,671,821,995  \n",
              "13228                                          1056,1139  \n",
              "13229                                                495  \n",
              "\n",
              "[13230 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneID</th>\n",
              "      <th>UTR5_len</th>\n",
              "      <th>Exon_Junctions_In_Full_Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>112</td>\n",
              "      <td>199,388,463,562,697,781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>222</td>\n",
              "      <td>387,573,687,744,847,959,1037,1177,1362,1534,16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>700</td>\n",
              "      <td>766,871,1012,1178,1263,1402,1483,1548,1697,182...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>289</td>\n",
              "      <td>515,618,717,821,971,1127,1307,1384,1538,1670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000971</td>\n",
              "      <td>240</td>\n",
              "      <td>298,484,590,667,859,1030,1204,1399,1576,1759,1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13225</th>\n",
              "      <td>ENSG00000278615</td>\n",
              "      <td>48</td>\n",
              "      <td>87,212,310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13226</th>\n",
              "      <td>ENSG00000278619</td>\n",
              "      <td>239</td>\n",
              "      <td>781,875,1008,1128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13227</th>\n",
              "      <td>ENSG00000278845</td>\n",
              "      <td>161</td>\n",
              "      <td>227,405,523,622,671,821,995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13228</th>\n",
              "      <td>ENSG00000280789</td>\n",
              "      <td>574</td>\n",
              "      <td>1056,1139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13229</th>\n",
              "      <td>ENSG00000281991</td>\n",
              "      <td>330</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13230 rows × 3 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromosomes = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Kelley_et_al_chromosomes.txt', delimiter = \"\\t\")\n",
        "chromosomes"
      ],
      "metadata": {
        "id": "N_zoThwx0u0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "88a7c576-69ed-42f5-9d17-9e1ace98e28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                GeneID  Chromosome\n",
              "0      ENSG00000186092           1\n",
              "1      ENSG00000279928           1\n",
              "2      ENSG00000279457           1\n",
              "3      ENSG00000278566           1\n",
              "4      ENSG00000273547           1\n",
              "...                ...         ...\n",
              "20290  ENSG00000277856  KI270726.1\n",
              "20291  ENSG00000275063  KI270726.1\n",
              "20292  ENSG00000271254  KI270711.1\n",
              "20293  ENSG00000277475  KI270713.1\n",
              "20294  ENSG00000268674  KI270713.1\n",
              "\n",
              "[20295 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneID</th>\n",
              "      <th>Chromosome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000186092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000279928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000279457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000278566</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000273547</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20290</th>\n",
              "      <td>ENSG00000277856</td>\n",
              "      <td>KI270726.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20291</th>\n",
              "      <td>ENSG00000275063</td>\n",
              "      <td>KI270726.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20292</th>\n",
              "      <td>ENSG00000271254</td>\n",
              "      <td>KI270711.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20293</th>\n",
              "      <td>ENSG00000277475</td>\n",
              "      <td>KI270713.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20294</th>\n",
              "      <td>ENSG00000268674</td>\n",
              "      <td>KI270713.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20295 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromosomes['Chromosome'].value_counts()"
      ],
      "metadata": {
        "id": "i7fzASja1JI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252b47ac-9be9-4619-da16-f3ab62643f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1             2053\n",
              "19            1458\n",
              "11            1316\n",
              "2             1298\n",
              "17            1185\n",
              "3             1070\n",
              "6             1045\n",
              "12            1033\n",
              "7              980\n",
              "5              868\n",
              "16             865\n",
              "X              824\n",
              "14             824\n",
              "9              772\n",
              "4              747\n",
              "10             730\n",
              "8              670\n",
              "15             609\n",
              "20             541\n",
              "22             489\n",
              "13             320\n",
              "18             269\n",
              "21             233\n",
              "Y               54\n",
              "MT              13\n",
              "KI270728.1       6\n",
              "KI270727.1       4\n",
              "KI270734.1       3\n",
              "GL000194.1       2\n",
              "GL000195.1       2\n",
              "KI270726.1       2\n",
              "KI270713.1       2\n",
              "GL000009.2       1\n",
              "GL000205.2       1\n",
              "GL000219.1       1\n",
              "GL000213.1       1\n",
              "GL000218.1       1\n",
              "KI270731.1       1\n",
              "KI270721.1       1\n",
              "KI270711.1       1\n",
              "Name: Chromosome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XRaMXVFv1YvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbp_k = np.load(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\RBP_k.npy')\n",
        "rbp_k.shape"
      ],
      "metadata": {
        "id": "pNwe4p0T4_u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068964d0-9afb-4292-e63e-ac007c7dffce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13230, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So not only do we have much more chromosomes, we the data comes from Pedro (df), Saluki (the sequences), from Pauline (chromosomes, exon junctions, via Saluki-chosen transcript), and from Yasmine (RBPs using Deepripe).\n",
        "Thus we should take good care that we merge the tables correctly."
      ],
      "metadata": {
        "id": "ITVKHQAf5c5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'geneID': UTR5_identifiers, 'UTR5_seqs': UTR5_seqs}\n",
        "UTR5 = pd.DataFrame(data=d)\n",
        "d = {'geneID': ORF_identifiers, 'ORF_seqs': ORF_seqs}\n",
        "ORF = pd.DataFrame(data=d)\n",
        "d = {'geneID': UTR3_identifiers, 'UTR3_seqs': UTR3_seqs}\n",
        "UTR3 = pd.DataFrame(data=d)\n",
        "\n",
        "#merge every data frame to sequences\n",
        "halflife = hl[[\"Ensembl Gene Id\", \"zscore\"]] # half-life\n",
        "seqs = pd.merge(pd.merge(UTR5, ORF, on ='geneID'), UTR3, on = 'geneID') # Sequence\n",
        "sequences = pd.merge(halflife, seqs, right_on = 'geneID', left_on = 'Ensembl Gene Id') # half-life + Sequence\n",
        "sequences = sequences.drop(columns=[\"geneID\"])\n",
        "sequences = sequences.rename(columns={\"Ensembl Gene Id\": \"geneID\"})\n",
        "sequences = pd.merge(sequences, chromosomes, left_on='geneID', right_on='GeneID') # halflife + Sequence + chromosomes\n",
        "sequences = sequences.drop(columns=[\"GeneID\"])\n",
        "sequences = pd.merge(sequences, exons, left_on='geneID', right_on='GeneID')# halflife + Sequence + chromosomes + exons\n",
        "sequences = sequences.drop(columns=[\"GeneID\"])\n",
        "\n",
        "#transform seqs into strings:\n",
        "sequences[\"UTR5_seqs\"] = sequences[\"UTR5_seqs\"].apply(str)\n",
        "sequences[\"UTR3_seqs\"] = sequences[\"UTR3_seqs\"].apply(str)\n",
        "sequences[\"ORF_seqs\"] = sequences[\"ORF_seqs\"].apply(str)\n",
        "\n",
        "rubbish = [d, UTR3, ORF, UTR5, UTR5_seqs, UTR3_seqs, ORF_seqs, UTR3_identifiers, UTR5_identifiers, ORF_identifiers, hl, halflife]\n",
        "del rubbish\n",
        "\n",
        "sequences.head()"
      ],
      "metadata": {
        "id": "M7rLipk85dwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "b2bee2b1-845a-4c3a-86f7-9ccf7a249077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            geneID    zscore  \\\n",
              "0  ENSG00000000003  1.807620   \n",
              "1  ENSG00000000457 -1.446182   \n",
              "2  ENSG00000000460  0.092022   \n",
              "3  ENSG00000000938 -0.196955   \n",
              "4  ENSG00000000971  1.611324   \n",
              "\n",
              "                                           UTR5_seqs  \\\n",
              "0  AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGG...   \n",
              "1  TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCC...   \n",
              "2  GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTT...   \n",
              "3  GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCC...   \n",
              "4  ACAGCATTAACATTTAGTGGGAGTGCAGTGAGAATTGGGTTTAACT...   \n",
              "\n",
              "                                            ORF_seqs  \\\n",
              "0  ATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTT...   \n",
              "1  ATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAAC...   \n",
              "2  ATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCT...   \n",
              "3  ATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCA...   \n",
              "4  ATGAGACTTCTAGCAAAGATTATTTGCCTTATGTTATGGGCTATTT...   \n",
              "\n",
              "                                           UTR3_seqs Chromosome  UTR5_len  \\\n",
              "0  CCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTT...          X       112   \n",
              "1  CAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTA...          1       222   \n",
              "2  AACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAA...          1       700   \n",
              "3  CCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGC...          1       289   \n",
              "4  AATCAATCATAAAGTGCACACCTTTATTCAGAACTTTAGTATTAAA...          1       240   \n",
              "\n",
              "                     Exon_Junctions_In_Full_Sequence  \n",
              "0                            199,388,463,562,697,781  \n",
              "1  387,573,687,744,847,959,1037,1177,1362,1534,16...  \n",
              "2  766,871,1012,1178,1263,1402,1483,1548,1697,182...  \n",
              "3       515,618,717,821,971,1127,1307,1384,1538,1670  \n",
              "4  298,484,590,667,859,1030,1204,1399,1576,1759,1...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geneID</th>\n",
              "      <th>zscore</th>\n",
              "      <th>UTR5_seqs</th>\n",
              "      <th>ORF_seqs</th>\n",
              "      <th>UTR3_seqs</th>\n",
              "      <th>Chromosome</th>\n",
              "      <th>UTR5_len</th>\n",
              "      <th>Exon_Junctions_In_Full_Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>1.807620</td>\n",
              "      <td>AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGG...</td>\n",
              "      <td>ATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTT...</td>\n",
              "      <td>CCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTT...</td>\n",
              "      <td>X</td>\n",
              "      <td>112</td>\n",
              "      <td>199,388,463,562,697,781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>-1.446182</td>\n",
              "      <td>TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCC...</td>\n",
              "      <td>ATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAAC...</td>\n",
              "      <td>CAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTA...</td>\n",
              "      <td>1</td>\n",
              "      <td>222</td>\n",
              "      <td>387,573,687,744,847,959,1037,1177,1362,1534,16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>0.092022</td>\n",
              "      <td>GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTT...</td>\n",
              "      <td>ATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCT...</td>\n",
              "      <td>AACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>700</td>\n",
              "      <td>766,871,1012,1178,1263,1402,1483,1548,1697,182...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>-0.196955</td>\n",
              "      <td>GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCC...</td>\n",
              "      <td>ATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCA...</td>\n",
              "      <td>CCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGC...</td>\n",
              "      <td>1</td>\n",
              "      <td>289</td>\n",
              "      <td>515,618,717,821,971,1127,1307,1384,1538,1670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000971</td>\n",
              "      <td>1.611324</td>\n",
              "      <td>ACAGCATTAACATTTAGTGGGAGTGCAGTGAGAATTGGGTTTAACT...</td>\n",
              "      <td>ATGAGACTTCTAGCAAAGATTATTTGCCTTATGTTATGGGCTATTT...</td>\n",
              "      <td>AATCAATCATAAAGTGCACACCTTTATTCAGAACTTTAGTATTAAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>298,484,590,667,859,1030,1204,1399,1576,1759,1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 10000 #this is slightly longer than the 95% quantile, but lower than Saluki's implementation\n",
        "\n",
        "seqs = sequences['UTR5_seqs'] + sequences['ORF_seqs'] + sequences['UTR3_seqs']\n",
        "def pad_sequence(seqs, max_len, anchor='start', value='N'):\n",
        "  padded_seqs = [fixed_len(seq, max_len, anchor=anchor) for seq in seqs.astype(\"string\")]\n",
        "  return padded_seqs\n",
        "fixed_len_seqs = np.array(pad_sequence(seqs, max_len))\n",
        "print(fixed_len_seqs[0:4])\n",
        "del seqs\n",
        "print(fixed_len_seqs.shape)"
      ],
      "metadata": {
        "id": "y8oUTj9w-XQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efe0b56-28f8-45b6-8666-db8d46b6d3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGGGGACTCCGCGTCTCGCTCTCTGTGTTCCAATCGCCCGGTGCGGTGGTGCAGGGTCTCGGGCTAGTCATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTTGTTTCAAGAGCGTTCTGCTAATCTACACTTTTATTTTCTGGATCACTGGCGTTATCCTTCTTGCAGTTGGCATTTGGGGCAAGGTGAGCCTGGAGAATTACTTTTCTCTTTTAAATGAGAAGGCCACCAATGTCCCCTTCGTGCTCATTGCTACTGGTACCGTCATTATTCTTTTGGGCACCTTTGGTTGTTTTGCTACCTGCCGAGCTTCTGCATGGATGCTAAAACTGTATGCAATGTTTCTGACTCTCGTTTTTTTGGTCGAACTGGTCGCTGCCATCGTAGGATTTGTTTTCAGACATGAGATTAAGAACAGCTTTAAGAATAATTATGAGAAGGCTTTGAAGCAGTATAACTCTACAGGAGATTATAGAAGCCATGCAGTAGACAAGATCCAAAATACGTTGCATTGTTGTGGTGTCACCGATTATAGAGATTGGACAGATACTAATTATTACTCAGAAAAAGGATTTCCTAAGAGTTGCTGTAAACTTGAAGATTGTACTCCACAGAGAGATGCAGACAAAGTAAACAATGAAGGTTGTTTTATAAAGGTGATGACCATTATAGAGTCAGAAATGGGAGTCGTTGCAGGAATTTCCTTTGGAGTTGCTTGCTTCCAACTGATTGGAATCTTTCTCGCCTACTGCCTCTCTCGTGCCATAACAAATAACCAGTATGAGATAGTGCCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTTAGGGTCCCCCCTGTGAATTAGAAAGTTGCTTGGCTGGAGAACTGACAACACTACTTACTGATAGACCAAAAAACTACACCAGTAGGTTGATTCAATCAAGATGTATGTAGACCTAAAACTACACCAATAGGCTGATTCAATCAAGATCCGTGCTCGCAGTGGGCTGATTCAATCAAGATGTATGTTTGCTATGTTCTAAGTCCACCTTCTATCCCATTCATGTTAGATCGTTGAAACCCTGTATCCCTCTGAAACACTGGAAGAGCTAGTAAATTGTAAATGAAGTAATACTGTGTTCCTCTTGACTGTTATTTTTCTTAGTAGGGGGCCTTTGGAAGGCACTGTGAATTTGCTATTTTGATGTAGTGTTACAAGATGGAAAATTGATTCCTCTGACTTTGCTATTGATGTAGTGTGATAGAAAATTCACCCCTCTGAACTGGCTCCTTCCCAGTCAAGGTTATCTGGTTTGATTGTATAATTTGCACCAAGAAGTTAAAATGTTTTATGACTCTCTGTTCTGCTGACAGGCAGAGAGTCACATTGTGTAATTTAATTTCAGTCAGTCAATAGATGGCATCCCTCATCAGGGTTGCCAGATGGTGATAACAGTGTAAGGCCTTGGGTCTAAGGCATCCACGACTGGAAGGGACTACTGATGTTCTGTGATACATCAGGTTTCAGCACACAACTTACATTTCTTTGCCTCCAAATTGAGGCATTTATTATGATGTTCATACTTTCCCTCTTGTTTGAAAGTTTCTAATTATTAAATGGTGTCGGAATTGTTGTATTTTCCTTAGGAATTCAGTGGAACTTATCTTCATTAAATTTAGCTGGTACCAGGTTGATATGACTTGTCAATATTATGGTCAACTTTAAGTCTTAGTTTTCGTTTGTGCCTTTGATTAATAAGTATAACTCTTATACAATAAATACTGCTTTCCTCTAAAAAGATCGTGTTTAAATTAACTTGTAGAAAATCTGCTGGAATGGTTGTTGTTTTCCACTGAGAAAGCTAAGCCCTACATTTCTATTCAGAGTACTGTTTTTAGATGTGAAATATAAGCCTGCGGCCTTAACTCTGTATTAAAAAAAATGTTTTTGTTTAAAAAAAACTGTTCCCATAGGTGCAGCAAACCACCATGGCACATGTATACCTATGTAACAAACCTGCACATTCTGCACATGTATCCCAGAACTTAATGTAAACAAAAAAATCTTAAAGTGCAAATATTAAAAAAAACTGTTCTCTGTGAAAAAAATTATATTCCATGTTATAAAGTAGCATATGACTAGTGTTCTCCTAGNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCCCCCAGAAGATTGTGGGTGTAGTGGCCACAGCCTTACAGGCAGGCAGGGGTGGTTGGTGTCAACAGGGGGGCCAACAGGGTACCAGAGCCAAGACCCTCGGCCTCCTCCCCCGCCGCCTTCCTGCAGATCTGCTTGGCTTTGAGGAAGAGTGGCAGTACTGCCTCACTGCATAAGGGATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAACCACCATTTACCTTACCCTCTGGACTTGCTGTTTATCCCGCTGTACTGCAAGATGGCAAATTTGCTTCAGTTTTTGTGTATAAGAGAGAAAATGAAGACAAGGTTAATAAAGCTGCCAAGCATTTGAAGACACTTCGTCACCCTTGCTTGCTAAGATTTTTATCTTGTACTGTGGAAGCGGATGGCATTCATCTTGTCACTGAGCGAGTACAGCCCCTGGAAGTGGCTTTGGAAACATTGTCTTCTGCAGAGGTCTGTGCTGGGATCTATGACATATTGCTGGCTCTTATCTTCCTTCATGACAGAGGACACCTAACACACAATAATGTCTGTTTATCATCTGTGTTTGTGAGTGAAGATGGACACTGGAAGCTAGGAGGAATGGAAACTGTTTGTAAAGTTTCTCAGGCCACACCAGAGTTTCTGAGGAGTATTCAGTCAATAAGAGACCCAGCATCTATCCCTCCTGAAGAGATGTCTCCAGAATTCACAACTCTCCCAGAGTGTCATGGACATGCCCGGGATGCCTTTTCATTTGGAACATTGGTGGAAAGTTTGCTCACAATCTTAAATGAACAGGTTTCAGCGGATGTTCTCTCCAGCTTTCAACAGACCTTGCACTCAACTTTGCTGAATCCCATTCCAAAATGTCGGCCAGCGCTCTGCACCTTACTATCTCATGACTTCTTCAGAAATGATTTTCTGGAAGTTGTGAATTTCTTGAAAAGTTTAACATTGAAGAGTGAAGAGGAGAAAACGGAATTCTTTAAATTTCTGCTGGACAGAGTCAGCTGCTTGTCAGAGGAATTGATAGCTTCAAGGTTGGTGCCTCTTCTGCTTAATCAGTTGGTGTTTGCAGAGCCAGTGGCTGTTAAGAGTTTTCTTCCTTATCTGCTTGGCCCCAAAAAAGATCATGCGCAGGGAGAAACTCCTTGCTTGCTCTCACCAGCCCTGTTCCAGTCACGGGTGATCCCCGTGCTTCTCCAGTTGTTTGAAGTTCATGAAGAGCATGTGCGGATGGTGCTGCTGTCTCACATCGAGGCCTACGTGGAGCACTTCACTCAGGAGCAGCTGAAGAAAGTCATCTTGCCACAGGTTTTGCTGGGCCTGCGTGATACTAGCGATTCCATTGTGGCAATTACTCTGCATAGCCTAGCAGTGCTGGTCTCTCTGCTTGGACCAGAGGTGGTTGTGGGAGGAGAACGAACCAAGATCTTCAAACGCACTGCCCCAAGTTTTACTAAAAATACTGACCTTTCTCTAGAAGATTCTCCTATGTGTGTCGTCTGCAGCCATCACAGTCAGATCTCGCCAATCTTGGAGAACCCCTTCTCTAGCATATTCCCTAAATGTTTCTTTTCTGGCAGCACGCCCATCAACAGCAAGAAGCACATACAGCGAGATTACTACAATACTCTTTTACAGACAGGCGATCCATTTTCTCAGCCTATTAAATTTCCCATAAATGGACTCTCAGATGTAAAAAATACTTCGGAGGACAGTGAAAACTTCCCATCAAGTTCTAAAAAGTCTGAGGAGTGGCCTGACTGGAGTGAACCTGAGGAGCCTGAAAATCAAACTGTCAACATACAGATTTGGCCTAGAGAACCTTGTGATGATGTCAAGTCCCAGTGCACTACCTTGGATGTGGAAGAGTCATCTTGGGATGACTGCGAGCCCAGCAGCTTAGATACTAAAGTAAACCCAGGAGGTGGAATCACTGCTACAAAACCTGTTACCTCAGGGGAGCAGAAGCCTATTCCTGCTTTGCTTTCACTCACTGAAGAGTCTATGCCTTGGAAATCAAGCTTACCCCAAAAGATTAGCCTTGTACAAAGGGGGGATGACGCAGACCAAATCGAGCCGCCAAAAGTGTCATCACAAGAAAGGCCCCTTAAGGTTCCATCAGAACTTGGTTTAGGAGAGGAATTCACCATTCAAGTAAAAAAGAAGCCAGTAAAAGATCCTGAGATGGATTGGTTTGCTGATATGATCCCAGAAATTAAGCCTTCTGCTGCTTTTCTTATATTACCTGAACTGAGGACAGAAATGGTCCCAAAAAAGGATGATGTCTCCCCAGTGATGCAGTTTTCCTCAAAATTTGCTGCAGCAGAAATTACTGAGGGAGAGGCTGAAGGCTGGGAAGAAGAAGGGGAGCTGAACTGGGAAGATAATAACTGGCAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTAAAAAAAATCAATACCTCAAAAGCAGGCTTTGGGACAAGAAAACCCCAAAGTGGCCTGCTTTTCCCATCCCAGGAGCTCATTATCCAGTCTGTGCCAACTGAAGTAGGAGACTGACTGTGAGTGCTGGCTAAAAGCCCTGGGTGGTGAGGCTCACAGTACTGGTTTCCAGGAGGAAGAGCCTTTGTGCATTTGACTGAGGCCAGTTTCTATGAAGAGCAAGTAGCTGAGGAGAGGTCGAATTTACTGCTTTTTCCAGGACAATTCTGGAAGTAAAGAAAATGTAATTCAAGCTGGTTAGCTTAATTTTGTGCCATTCTTTAACATAAGAGTAAGCTCTATTATGAAATACAACTTTAAAAAATTTTAGCTATAAATTATATAAATGATTTTAAATTGCTGAGGTTTCCTTAGGCAGCTTATTTATTTGTTTACAGTTAGACTATCTGAGTAAATGGTTCTTTGTGGACCTAGGCAGTTCCTGACTGTTCCACATGTAGTACATTGTACCAAAGTTCTTAATAAGAATATTCCCCACAATCCTGTTCTCTAAATGTCAAATAAAGATTATTTTCACTAGATTCAACTTTACAAAANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTTTTAGCAGTGGATGTGGCGTTTTCTTCCATTCCTTCTTTCAGTTTTTCTGTACTCGTTGCTTGCAATTAAGTGTAAATACTTTTGCTAGTGGATAATGGGGGAGGCAAGGACTGAGACCTGCGGTATGACGATAGCTCTGGCTCTTAATAGTTTGAGGTAAAGCGAGATACTCTGAGCTTTTGTCTCCCGTAAAAAGGGTGGTGAATATGAATAAGGGCTTTCTTAGCGTTATAAGAATTAAAGGGCATAGTTCTGTGGTGTGAAATCTTTAAAAGATGTTCAGTAAATAAAAATGATTTTCCTCCTTCCCCTCTCAGACCTCTTTTTCTTCTTTCTTTCTTTTTTTTTGACAAGTTCTCACTCCTCTCACCCAGGCTGGAGTCTTTCTGAAAGAGTTCTTCCGCTTGTTGTTGGCTTTCAACTGTTGGATTTGAGGCGCTTAGCGCCTTCTTCGTCCGGGTGCAGCACATTCTTGATTGGTCTCATGCCTTTGTGGTTGTAAATGTGCCTGGAATCCTAGCCTTTCATGGTTTGTTCTGAGTAATGAATACCCTATTACTATGATACTAGTATCTTCCTTAATTATCCTACTCATTGTCTCAACATTCTGACAGTTGGATTGAGCATATTCAAATTTTGAAAATTATTGTAGAAATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCTTTTCACAAGTGTTACCAAAGACTGTGAAATTATTCGATGACATGATGTATGAATTAACCAGTCAAGCCAGAGGACTGTCAAGCCAAAATTTGGAAATCCAGACCACTCTAAGGAATATTTTACAAACAATGGTGCAGCTCTTAGGAGCTCTCACAGGATGTGTTCAGCATATCTGTGCCACACAGGAATCCATCATTTTGGAAAATATTCAGAGTCTCCCCTCCTCAGTCCTTCATATAATTAAAAGCACATTTGTGCATTGTAAGAATAGTGAATCTGTGTATTCTGGGTGTTTACACCTAGTTTCAGACCTTCTCCAGGCTCTTTTCAAGGAGGCCTATTCTCTTCAAAAGCAGTTAATGGAACTGCTGGACATGGTTTGCATGGACCCTTTAGTAGATGACAATGATGATATTTTGAATATGGTAATAGTTATTCATTCTTTATTGGATATCTGCTCTGTTATTTCCAGTATGGACCATGCATTTCATGCCAATACTTGGAAGTTTATAATTAAGCAGAGCCTTAAGCACCAGTCCATAATAAAAAGCCAGTTGAAACACAAAGATATAATTACTAGCTTGTGTGAAGACATTCTTTTCTCCTTCCATTCTTGTTTACAGTTAGCTGAGCAGATGACACAGTCAGATGCACAGGATAATGCTGACTACAGATTATTTCAGAAAACACTCAAATTGTGTCGTTTTTTTGCCAACTCCCTTTTGCACTACGCTAAGGAATTTCTTCCTTTCCTCTCTGATTCTTGCTGTACTTTGCACCAACTGTATCTTCAGATACACAGCAAGTTTCCTCCAAGCCTTTATGCTACCAGGATTTCTAAAGCACACCAAGAGGAAATAGCAGGTGCTTTCCTAGTGACACTGGATCCACTTATCAGTCAGCTGCTCACATTTCAGCCTTTCATGCAGGTGGTTTTGGACAGTAAATTAGACCTGCCATGTGAACTGCAGTTTCCACAATGTCTTCTTCTGGTTGTTGTCATGGATAAGCTGCCATCTCAGCCTAAGGAAGTGCAAACCCTGTGGTGCACAGACAGCCAGGTCTCAGAAACGACAACCAGGATATCTCTACTCAAAGCCGTTTTCTACAGTTTTGAGCAGTGTTCTGGTGAACTCTCTCTACCTGTTCATTTACAGGGATTAAAGAGTAAGGGGAAAGCTGAGGTGGCTGTCACCTTGTATCAGCATGTTTGTGTTCATCTGTGTACATTTATTACTTCCTTTCATCCCTCACTGTTTGCTGAACTGGATGCTGCTCTGCTGAATGCTGTACTTAGTGCTAATATGATCACCTCTTTGTTAGCTATGGATGCATGGTGCTTCCTTGCTCGATATGGGACTGCTGAACTGTGTGCACACCATGTCACCATAGTGGCTCATCTGATAAAGTCATGCCCTGGAGAATGTTATCAACTCATCAACCTATCAATACTGTTGAAGCGTCTCTTTTTCTTCATGGCACCACCCCATCAGCTGGAGTTTATCCAGAAATTTTCCCCAAAAGAAGCAGAAAATCTGCCTCTGTGGCAACATATTTCCTTCCAGGCGTTACCTCCTGAGCTTAGGGAACAAACTGTCCATGAGGTCACCACAGTAGGCACTGCAGAATGCAGGAAATGGCTGAGCAGGAGTCGTACTTTGGGAGAACTAGAATCTCTGAACACAGTACTGTCTGCTTTGCTTGCAGTATGTAATTCTGCTGGTGAAGCTTTGGATACAGGAAAACAAACTGCAATTATCGAAGTTGTGAGTCAGCTTTGGGCTTTTTTAAACATTAAACAGGTAGCAGATCAACCTTATGTTCAACAGACATTCAGCCTTTTACTTCCACTGTTGGGATTTTTCATTCAAACTCTAGATCCTAAACTGATACTTCAGGCAGTAACTTTGCAGACCTCGCTACTTAAATTAGAGCTTCCTGACTATGTTCGTTTGGCAATGTTGGATTTTGTATCTTCTTTAGGAAAACTTTTTATACCTGAAGCTATCCAGGACAGAATTCTGCCCAACCTGTCCTGTATGTTTGCCTTACTGCTAGCTGACAGGAGTTGGCTGCTAGAACAACATACCTTGGAGGCGTTTACTCAGTTCGCTGAGGGAACAAATCATGAAGAGATAGTTCCACAGTGTCTCAGTTCTGAAGAAACTAAGAACAAAGTTGTATCCTTTCTGGAGAAGACTGGGTTTGTAGATGAAACTGAAGCTGCCAAAGTGGAACGTGTGAAACAGGAAAAAGGTATTTTCTGGGAACCCTTTGCTAATGTGACTGTAGAAGAAGCAAAGAGGTCATCTTTACAGCCTTATGCAAAAAGAGCTCGTCAGGAGTTCCCCTGGGAAGAAGAGTACAGGTCAGCGCTGCATACAATAGCAGGGGCTTTGGAAGCAACTGAGTCACTACTCCAAAAGGGTCCTGCTCCAGCCTGGCTTTCAATGGAAATGGAGGCGCTCCAAGAAAGGATGGATAAGCTAAAACGTTACATACATACTCTAGGGAACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAAATACTTATGTCTGTACATTTTCTAACAGATATAAAACAAATTTTGTAAAGTTGAATCTAGTGAAAATAATCTTTATTTGACATTTAGAGAACAGGATTGTGGGGAATATTCTTATTAAGAACTTTGGTACAATGTACTACATGTGGAACAGTCAGGAACTGCCTAGGTCCACAAAGAACCATTTACTCAGATAGTCTAACTGTAAACAAATAAATAAGCTGCCTAAGGAAACCTCAGCAATTTAAAATCATTTATATAATTTATAGCTAAAATTTTTTAAAGTTGTATTTCATAATAGAGCTTACTCTTATGTTAAAGAATGGCACAAAATTAAGCTAACCAGCTTGAATTACATTTTCTTTACTTCCAGAATTGTCCTGGAAAAAGCAGTAAATTCGACCTCTCCTCAGCTACTTGCTCTTCATAGAAACTGGCCTCAGTCAAATGCACAAAGGCTCTTCCTCCTGGAAACCAGTACTGTGAGCCTCACCACCCAGGGCTTTTAGCCAGCACTCACAGTCAGTCTCCTACTTCAGTTGGCACAGACTGGATAATGAGCTCCTGGGATGGGAAAAGCAGGCCACTTTGGGGTTTTCTTGTCCCAAAGCCTGCTTTTGAGGTATTGATTTTTTTTAAAAAAAGGGAATCCTTTTTCCTAAAGTTTAACTCACATCTATTGTCACCAGTTATTATCTTCCCAGTTCAGCTCCCCTTCTTCTTCCCAGCCTTCAGCCTCTCCCTGCAACAAAATAAAGCACACCAAGAACCCACTGAAACAAATCATATGCAAAAATCATACGCAAATTTGAAAAAGCAGGAATTTAAAATTTATCTTTTGATGCCAGAAACACTACCTCGTACTAAGTAAAATAACTTAGAGCTCTAACAGAAAGTTGAAAAGTAGGATTACAAAACCATGGCACTGGAAAATAGCTTTTCAAAAACCATAAAATCCAGTAAAAATCAGTGTGGATGACACCAAATCCTTATTTTAATCCCTTTTTTTTCTTTTTCAAATAAAAAGGTTACAATAGCTCATTAAACAAANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCCGCCGGCCGTGACTGCAATAAGAGAAGTCCGAGGCGGCTTCCTCCTCCCTGCCCAGCAGGGGCGGCGGTCAGAGGCGGGCAGCACCCCAGTTCTCCCCGCACGCCGGCACTCGCGGCTGCTGGAGCCCCGGCTGGCTCACCCCGGGGCCGGGCAGAATTGGGCTCCAGGTCTCTGACCCCTCCCAAGGATCATGCCGCAGCCCCACTGACCCAGGAGTAGGGGCCTAAGGGCAGGGAACCTGGAATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCAAGGAGGATGCTGGCCTGGAAGGGGACTTCAGAAGCTACGGGGCAGCAGACCACTATGGGCCTGACCCCACTAAGGCCCGGCCTGCATCCTCATTTGCCCACATCCCCAACTACAGCAACTTCTCCTCTCAGGCCATCAACCCTGGCTTCCTTGATAGTGGCACCATCAGGGGTGTGTCAGGGATTGGGGTGACCCTGTTCATTGCCCTGTATGACTATGAGGCTCGAACTGAGGATGACCTCACCTTCACCAAGGGCGAGAAGTTCCACATCCTGAACAATACTGAAGGTGACTGGTGGGAGGCTCGGTCTCTCAGCTCCGGAAAAACTGGCTGCATTCCCAGCAACTACGTGGCCCCTGTTGACTCAATCCAAGCTGAAGAGTGGTACTTTGGAAAGATTGGGAGAAAGGATGCAGAGAGGCAGCTGCTTTCACCAGGCAACCCCCAGGGGGCCTTTCTCATTCGGGAAAGCGAGACCACCAAAGGTGCCTACTCCCTGTCCATCCGGGACTGGGATCAGACCAGAGGCGATCATGTGAAGCATTACAAGATCCGCAAACTGGACATGGGCGGCTACTACATCACCACACGGGTTCAGTTCAACTCGGTGCAGGAGCTGGTGCAGCACTACATGGAGGTGAATGACGGGCTGTGCAACCTGCTCATCGCGCCCTGCACCATCATGAAGCCGCAGACGCTGGGCCTGGCCAAGGACGCCTGGGAGATCAGCCGCAGCTCCATCACGCTGGAGCGCCGGCTGGGCACCGGCTGCTTCGGGGATGTGTGGCTGGGCACGTGGAACGGCAGCACTAAGGTGGCGGTGAAGACGCTGAAGCCGGGCACCATGTCCCCGAAGGCCTTCCTGGAGGAGGCGCAGGTCATGAAGCTGCTGCGGCACGACAAGCTGGTGCAGCTGTACGCCGTGGTGTCGGAGGAGCCCATCTACATCGTGACCGAGTTCATGTGTCACGGCAGCTTGCTGGATTTTCTCAAGAACCCAGAGGGCCAGGATTTGAGGCTGCCCCAATTGGTGGACATGGCAGCCCAGGTAGCTGAGGGCATGGCCTACATGGAACGCATGAACTACATTCACCGCGACCTGAGGGCAGCCAACATCCTGGTTGGGGAGCGGCTGGCGTGCAAGATCGCAGACTTTGGCTTGGCGCGTCTCATCAAGGACGATGAGTACAACCCCTGCCAAGGTTCCAAGTTCCCCATCAAGTGGACAGCCCCAGAAGCTGCCCTCTTTGGCAGATTCACCATCAAGTCAGACGTGTGGTCCTTTGGGATCCTGCTCACTGAGCTCATCACCAAGGGCCGAATCCCCTACCCAGGCATGAATAAACGGGAAGTGTTGGAACAGGTGGAGCAGGGCTACCACATGCCGTGCCCTCCAGGCTGCCCAGCATCCCTGTACGAGGCCATGGAACAGACCTGGCGTCTGGACCCGGAGGAGAGGCCTACCTTCGAGTACCTGCAGTCCTTCCTGGAGGACTACTTCACCTCCGCTGAACCACAGTACCAGCCCGGGGATCAGACACCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGCCAATCCCCAGAGCTGTTCTTCCAAAGCCCCCAGGCTGGCTTAGAACCCCATAGAGTCCTAGCATCACCGAGGACGTGGCTGCTCTGACACCACCTAGGGCAACCTACTTGTTTTACAGATGGGGCAAAAGGAGGCCCAGAGCTGATCTCTCATCCGCTCTGGCCCCAAGCACTATTTCTTCCTTTTCCACTTAGGCCCCTACATGCCTGTAGCCTTTCTCACTCCATCCCCACCCAAAGTGCTCAGACCTTGTCTAGTTATTTATAAAACTGTATGTACCTCCCTCACTTCTCTCCTATCACTGCTTTCCTACTCTCCTTTTATCTCACTCTAGTCCAGGTGCCAAGAATTTCCCTTCTACCCTCTATTCTCTTGTGTCTGTAAGTTACAAAGTCAGGAAAAGTCTTGGCTGGACCCCTTTCCTGCTGGGTGGATGCAGTGGTCCAGGACTGGGGTCTGGGCCCAGGTTTGAGGGAGAAGGTTGCAGAGCACTTCCCACCTCTCTGAATAGTGTGTATGTGTTGGTTTATTGATTCTGTAAATAAGTAAAATGACAATATGAATCCTCAAACCATGAAATACCCTTGAACCTTCCTTTGGGAGCGGGGGTGGTCAATAGGGGGTGAACGGACAGATATGGCTACAGGCAGCAGCAGGGGAAGCTGGAGAGGGCCCTAATGCCTACCAAGCACGGGGCATCCAAGGTGTGGAGTTTTAGAACACCCAGAGTCCCACTGCTCATCTGCACGTGAGTTTAGAAGACAAGCAGCTGAAGATACATTAAAATGTCCCCTTCGTTGCTGANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN']\n",
            "(13230,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot for track 1-4: the nucleotides \n",
        "\n",
        "one_hot_seqs = np.array([one_hot(seq, neutral_value=0) for seq in fixed_len_seqs])\n",
        "print(one_hot_seqs[0:2])\n",
        "print(one_hot_seqs.shape)\n",
        "rubbish = [fixed_len_seqs] \n",
        "del rubbish"
      ],
      "metadata": {
        "id": "PdyuPKVL_0QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1233d312-c9bc-4c23-bc2a-3fc5a85340e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]]\n",
            "(13230, 10000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot for track 5: the exon binding sites\n",
        "# dunno why, I guess I still suck at python, but this took me over an hours to code and bugfix\n",
        "# lol this is future me from the next day, this was wrong and I had redo all the training\n",
        "\n",
        "exons = []\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  onehot = np.repeat(0, repeats = max_len)\n",
        "  if(isinstance(sequences[\"Exon_Junctions_In_Full_Sequence\"][i], str)):\n",
        "    current_exons = list(map(int, sequences[\"Exon_Junctions_In_Full_Sequence\"][i].split(\",\")))\n",
        "    assert len(current_exons) > 0\n",
        "    positions_capped = [x for x in current_exons if x <= 10000] # delete all exon junctions after 10000 since we're capping the sequence there\n",
        "    onehot[positions_capped] = 1\n",
        "    '''\n",
        "    for j in current_exons:\n",
        "      positions = [x+len(sequences['UTR5_seqs'][i]) for x in current_exons] # have to add UTR5 length to indices\n",
        "      positions_capped = [x for x in positions if x <= 10000] # delete all exon junctions after 10000 since we're capping the sequence there\n",
        "      onehot[positions_capped] = 1 #exon junctions are 1 now\n",
        "      \n",
        "  if(isinstance(sequences[\"Exon_Junctions_In_Full_Sequence\"][i], float)):\n",
        "    if(not(math.isnan(sequences[\"Exon_Junctions_In_Full_Sequence\"][i]))):\n",
        "      onehot[int(sequences[\"Exon_Junctions_In_Full_Sequence\"][i])+len(sequences['UTR5_seqs'][i])] = 1\n",
        "    '''\n",
        "  exons.append(onehot)"
      ],
      "metadata": {
        "id": "27vK8R2SAD9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(map(int, sequences[\"Exon_Junctions_In_Full_Sequence\"][5].split(\",\"))))"
      ],
      "metadata": {
        "id": "VDsHa06rCEQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da85d0f4-595d-4c63-c766-a1b7db387bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[280, 468, 808, 1019, 1210, 1319]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot for track 6: Marking the beginning of each codon with 1\n",
        "starts = []\n",
        "for i in range(len(sequences)):\n",
        "  #assert len(sequences['ORF_seqs'].astype(\"string\")[i]) % 3 == 0 \n",
        "  lst = list(range(len(sequences['ORF_seqs'].astype(\"string\")[i])))\n",
        "  onehot = np.repeat(0, repeats = len(sequences['ORF_seqs'].astype(\"string\")[i]))\n",
        "  onehot[lst[0::3]] = 1\n",
        "  full = np.concatenate((np.repeat([0], repeats = len(sequences['UTR5_seqs'].astype(\"string\")[i])),\n",
        "                         onehot,\n",
        "                         np.repeat([0], repeats = len(sequences['UTR3_seqs'].astype(\"string\")[i]))), axis=None)\n",
        "  if (len(full) > max_len):\n",
        "    full = full[:max_len]\n",
        "  elif (len(full) < max_len):\n",
        "    full = np.concatenate((full, np.repeat(0, repeats = max_len - len(full))),axis = None)\n",
        "  starts.append(full)"
      ],
      "metadata": {
        "id": "pRuNTsz4AHLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rubbish = [fixed_len_seqs]\n",
        "\n",
        "rubbish = [fixed_len_seqs, d, UTR3, ORF, UTR5, UTR5_seqs, UTR3_seqs, ORF_seqs, hl,\n",
        "           UTR3_identifiers, UTR5_identifiers, ORF_identifiers, halflife, max_len]\n",
        "del rubbish"
      ],
      "metadata": {
        "id": "lt-QVEBiP5Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes about 18 GB, so beware of that\n",
        "onehot = np.concatenate((one_hot_seqs,np.array(exons)[:, :, None], np.array(starts)[:, :, None]), axis = 2)\n",
        "print(onehot.shape)"
      ],
      "metadata": {
        "id": "6ZpZoaGuPp3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ec15cd-7435-468b-e397-3bf3408de443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13230, 10000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del exons\n",
        "del starts"
      ],
      "metadata": {
        "id": "8qpC7Tr5RZae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for The Train-Val-Test split we split as recommended on Chromosomes:"
      ],
      "metadata": {
        "id": "oM3U9VTxSy0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chrom_val = ['2', '3', '4']\n",
        "chrom_test = ['1', '8', '9']"
      ],
      "metadata": {
        "id": "Ih4OOJxISyJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_test = np.where(sequences.Chromosome.isin(chrom_test))[0]\n",
        "idx_val = np.where(sequences.Chromosome.isin(chrom_val))[0]\n",
        "idx_train = np.where(~(sequences.Chromosome.isin(chrom_test)| sequences.Chromosome.isin(chrom_val)))[0]"
      ],
      "metadata": {
        "id": "FQcQCI4BTFSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(array, idx_train, idx_val, idx_test):\n",
        "  return array[idx_train], array[idx_val], array[idx_test]"
      ],
      "metadata": {
        "id": "k7GWuUtuTJxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(idx_test))\n",
        "print(len(idx_val))\n",
        "print(len(idx_train))"
      ],
      "metadata": {
        "id": "aOrm43s0Z8M2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9299d934-669c-4a7b-f3f2-96a9bdaaf148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2334\n",
            "2118\n",
            "8778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = train_test_split(onehot, idx_train, idx_val, idx_test)\n",
        "y_train, y_val, y_test = train_test_split(sequences['zscore'].values, idx_train, idx_val, idx_test)"
      ],
      "metadata": {
        "id": "mmpWExHRTfMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplainedVariance(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=10):\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            var_score = explained_variance_score(self.y_val, y_pred)\n",
        "            #r2 = r2_score(self.y_val, y_pred)\n",
        "            del y_pred\n",
        "            #print(\" - interval evaluation - epoch: {:d} - explained variance: {:.6f} - R2: {:.6f}\".format(epoch, var_score, r2))\n",
        "            print(\"interval evaluation - epoch: {:d} - explained variance: {:.6f}\".format(epoch, var_score))\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "xf5ZZA63U-qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saluki-Type model\n",
        "input = kl.Input((X_train.shape[1:]))\n",
        "\n",
        "x = kl.Conv1D(64, kernel_size=5, activation=None, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(input)\n",
        "x = tfa.layers.GroupNormalization(groups = 1, axis = 2)(x)\n",
        "x = kl.Activation(\"relu\")(x)\n",
        "x = kl.Dropout(0.3)(x)\n",
        "\n",
        "for i in range(6):\n",
        "  x = kl.Conv1D(64, kernel_size=5, activation=None, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(x)\n",
        "  x = kl.MaxPooling1D(pool_size=2)(x)\n",
        "  x = tfa.layers.GroupNormalization(groups = 1, axis = 2)(x)\n",
        "  x = kl.Activation(\"relu\")(x)\n",
        "  x = kl.Dropout(0.3)(x)\n",
        "\n",
        "x = kl.GRU(64, go_backwards=True, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(x) #backwards so it encounters padding first\n",
        "x = kl.BatchNormalization()(x)\n",
        "x = kl.Activation(\"relu\")(x)\n",
        "x = kl.Dropout(0.3)(x)\n",
        "\n",
        "x = kl.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(l=0.0005))(x) \n",
        "x = kl.Activation(\"relu\")(x)\n",
        "\n",
        "output = kl.Dense(units=1)(x)\n",
        "\n",
        "my_saluki = Model(inputs=input, outputs=output)\n",
        "my_saluki.summary()\n",
        "\n",
        "#Saluki: We chose layer normalization over batch normalization because most of the 3′ positions are zero padded and would confuse the batch statistics.\n"
      ],
      "metadata": {
        "id": "X0vIgaHIVpyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af4f2c0-f61b-4aa0-bada-08f2cf7a4de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 10000, 6)]        0         \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 9996, 64)          1984      \n",
            "                                                                 \n",
            " group_normalization_15 (Gro  (None, 9996, 64)         128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 9996, 64)          0         \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 9996, 64)          0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 9992, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 4996, 64)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_16 (Gro  (None, 4996, 64)         128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 4996, 64)          0         \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 4996, 64)          0         \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 4992, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 2496, 64)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_17 (Gro  (None, 2496, 64)         128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 2496, 64)          0         \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 2496, 64)          0         \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 2492, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 1246, 64)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_18 (Gro  (None, 1246, 64)         128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 1246, 64)          0         \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 1246, 64)          0         \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 1242, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPoolin  (None, 621, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_19 (Gro  (None, 621, 64)          128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 621, 64)           0         \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 621, 64)           0         \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 617, 64)           20544     \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPoolin  (None, 308, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_20 (Gro  (None, 308, 64)          128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 308, 64)           0         \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 308, 64)           0         \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 304, 64)           20544     \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPoolin  (None, 152, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " group_normalization_21 (Gro  (None, 152, 64)          128       \n",
            " upNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 152, 64)           0         \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 152, 64)           0         \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 159,809\n",
            "Trainable params: 159,681\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "hUAbPQFOV3mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02c609d-4001-482f-b3f0-2cc88dc856d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import datetime"
      ],
      "metadata": {
        "id": "aIP6jd9lV5o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So my GPU-memory is somewhat unstable and prone to error for batchsize bigger than 16, yet\n",
        "# batch size 16 works fine if I restart everything for every model.fit"
      ],
      "metadata": {
        "id": "mo9tczmEapVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "my_saluki.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.98, clipnorm=0.5),\n",
        "              loss=\"mse\")\n",
        "\n",
        "logdir = os.path.join(os.path.join(os.getcwd(), \"logs\"), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# Train the model\n",
        "history = my_saluki.fit(X_train, y_train,\n",
        "                        #X_train[0:200,:], y_train[0:200], \n",
        "                        validation_data=(X_val, y_val),  \n",
        "                        #validation_data=(X_val[0:100,:], y_val[0:100]),\n",
        "                        callbacks=[EarlyStopping(patience=25, restore_best_weights=True),   \n",
        "                                   History(),\n",
        "                                   ExplainedVariance(validation_data=(X_val, y_val), interval=4),\n",
        "                                   tensorboard_callback],\n",
        "                        batch_size=16,  #they used 64\n",
        "                        shuffle = True,\n",
        "                        epochs=1000)  "
      ],
      "metadata": {
        "id": "t13N24J-V8eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac4b29d-bb05-467c-8d19-01b66544ac05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "  5/549 [..............................] - ETA: 21s - loss: 1.9319WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0255s vs `on_train_batch_end` time: 0.0328s). Check your callbacks.\n",
            "549/549 [==============================] - ETA: 0s - loss: 1.3725interval evaluation - epoch: 0 - explained variance: 0.064991\n",
            "549/549 [==============================] - 37s 49ms/step - loss: 1.3725 - val_loss: 1.0099\n",
            "Epoch 2/1000\n",
            "549/549 [==============================] - 23s 42ms/step - loss: 1.1037 - val_loss: 0.9404\n",
            "Epoch 3/1000\n",
            "549/549 [==============================] - 23s 42ms/step - loss: 1.0229 - val_loss: 0.8668\n",
            "Epoch 4/1000\n",
            "549/549 [==============================] - 23s 42ms/step - loss: 0.9924 - val_loss: 0.9971\n",
            "Epoch 5/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.9452interval evaluation - epoch: 4 - explained variance: 0.164782\n",
            "549/549 [==============================] - 26s 48ms/step - loss: 0.9463 - val_loss: 0.7950\n",
            "Epoch 6/1000\n",
            "549/549 [==============================] - 25s 46ms/step - loss: 0.9189 - val_loss: 0.7893\n",
            "Epoch 7/1000\n",
            "549/549 [==============================] - 27s 48ms/step - loss: 0.8904 - val_loss: 0.8042\n",
            "Epoch 8/1000\n",
            "549/549 [==============================] - 27s 50ms/step - loss: 0.8649 - val_loss: 0.8417\n",
            "Epoch 9/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.8770interval evaluation - epoch: 8 - explained variance: 0.149535\n",
            "549/549 [==============================] - 29s 53ms/step - loss: 0.8772 - val_loss: 0.8015\n",
            "Epoch 10/1000\n",
            "549/549 [==============================] - 28s 51ms/step - loss: 0.8106 - val_loss: 0.7182\n",
            "Epoch 11/1000\n",
            "549/549 [==============================] - 30s 55ms/step - loss: 0.7376 - val_loss: 1.2078\n",
            "Epoch 12/1000\n",
            "549/549 [==============================] - 31s 57ms/step - loss: 0.7122 - val_loss: 1.3804\n",
            "Epoch 13/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.7031interval evaluation - epoch: 12 - explained variance: 0.295686\n",
            "549/549 [==============================] - 38s 70ms/step - loss: 0.7026 - val_loss: 0.6861\n",
            "Epoch 14/1000\n",
            "549/549 [==============================] - 42s 77ms/step - loss: 0.6929 - val_loss: 1.1408\n",
            "Epoch 15/1000\n",
            "549/549 [==============================] - 39s 72ms/step - loss: 0.6982 - val_loss: 2.1038\n",
            "Epoch 16/1000\n",
            "549/549 [==============================] - 38s 70ms/step - loss: 0.6950 - val_loss: 0.6565\n",
            "Epoch 17/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.6840interval evaluation - epoch: 16 - explained variance: 0.313797\n",
            "549/549 [==============================] - 45s 82ms/step - loss: 0.6840 - val_loss: 0.7244\n",
            "Epoch 18/1000\n",
            "549/549 [==============================] - 42s 76ms/step - loss: 0.6889 - val_loss: 0.9185\n",
            "Epoch 19/1000\n",
            "549/549 [==============================] - 47s 85ms/step - loss: 0.6799 - val_loss: 2.6159\n",
            "Epoch 20/1000\n",
            "549/549 [==============================] - 46s 83ms/step - loss: 0.6732 - val_loss: 0.6607\n",
            "Epoch 21/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6764interval evaluation - epoch: 20 - explained variance: 0.368783\n",
            "549/549 [==============================] - 50s 92ms/step - loss: 0.6764 - val_loss: 0.6994\n",
            "Epoch 22/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6569 - val_loss: 0.6344\n",
            "Epoch 23/1000\n",
            "549/549 [==============================] - 48s 87ms/step - loss: 0.6699 - val_loss: 0.9285\n",
            "Epoch 24/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6655 - val_loss: 0.6537\n",
            "Epoch 25/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6649interval evaluation - epoch: 24 - explained variance: 0.357979\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6649 - val_loss: 0.7896\n",
            "Epoch 26/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6620 - val_loss: 0.5928\n",
            "Epoch 27/1000\n",
            "549/549 [==============================] - 48s 88ms/step - loss: 0.6593 - val_loss: 0.7348\n",
            "Epoch 28/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6601 - val_loss: 0.5929\n",
            "Epoch 29/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6635interval evaluation - epoch: 28 - explained variance: 0.354854\n",
            "549/549 [==============================] - 50s 92ms/step - loss: 0.6635 - val_loss: 0.6597\n",
            "Epoch 30/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6526 - val_loss: 1.5843\n",
            "Epoch 31/1000\n",
            "549/549 [==============================] - 52s 95ms/step - loss: 0.6596 - val_loss: 0.6428\n",
            "Epoch 32/1000\n",
            "549/549 [==============================] - 52s 94ms/step - loss: 0.6572 - val_loss: 1.0481\n",
            "Epoch 33/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6538interval evaluation - epoch: 32 - explained variance: 0.353379\n",
            "549/549 [==============================] - 61s 112ms/step - loss: 0.6538 - val_loss: 1.0412\n",
            "Epoch 34/1000\n",
            "549/549 [==============================] - 56s 102ms/step - loss: 0.6512 - val_loss: 0.6042\n",
            "Epoch 35/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6491 - val_loss: 0.5887\n",
            "Epoch 36/1000\n",
            "549/549 [==============================] - 63s 116ms/step - loss: 0.6451 - val_loss: 0.6332\n",
            "Epoch 37/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6476interval evaluation - epoch: 36 - explained variance: 0.377144\n",
            "549/549 [==============================] - 60s 109ms/step - loss: 0.6476 - val_loss: 0.6141\n",
            "Epoch 38/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6531 - val_loss: 0.7526\n",
            "Epoch 39/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6426 - val_loss: 0.6626\n",
            "Epoch 40/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6500 - val_loss: 0.6289\n",
            "Epoch 41/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6444interval evaluation - epoch: 40 - explained variance: 0.368802\n",
            "549/549 [==============================] - 68s 124ms/step - loss: 0.6444 - val_loss: 0.6046\n",
            "Epoch 42/1000\n",
            "549/549 [==============================] - 64s 117ms/step - loss: 0.6458 - val_loss: 0.8622\n",
            "Epoch 43/1000\n",
            "549/549 [==============================] - 57s 103ms/step - loss: 0.6448 - val_loss: 0.7050\n",
            "Epoch 44/1000\n",
            "549/549 [==============================] - 65s 119ms/step - loss: 0.6527 - val_loss: 0.5878\n",
            "Epoch 45/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6432interval evaluation - epoch: 44 - explained variance: 0.389243\n",
            "549/549 [==============================] - 69s 125ms/step - loss: 0.6432 - val_loss: 0.5724\n",
            "Epoch 46/1000\n",
            "549/549 [==============================] - 64s 117ms/step - loss: 0.6438 - val_loss: 0.6776\n",
            "Epoch 47/1000\n",
            "549/549 [==============================] - 54s 99ms/step - loss: 0.6465 - val_loss: 0.7464\n",
            "Epoch 48/1000\n",
            "549/549 [==============================] - 71s 129ms/step - loss: 0.6442 - val_loss: 0.5767\n",
            "Epoch 49/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6377interval evaluation - epoch: 48 - explained variance: 0.300588\n",
            "549/549 [==============================] - 71s 130ms/step - loss: 0.6377 - val_loss: 0.8382\n",
            "Epoch 50/1000\n",
            "549/549 [==============================] - 71s 130ms/step - loss: 0.6427 - val_loss: 0.7708\n",
            "Epoch 51/1000\n",
            "549/549 [==============================] - 58s 105ms/step - loss: 0.6392 - val_loss: 0.9638\n",
            "Epoch 52/1000\n",
            "549/549 [==============================] - 61s 111ms/step - loss: 0.6410 - val_loss: 0.7180\n",
            "Epoch 53/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6349interval evaluation - epoch: 52 - explained variance: 0.363565\n",
            "549/549 [==============================] - 68s 125ms/step - loss: 0.6349 - val_loss: 0.6653\n",
            "Epoch 54/1000\n",
            "549/549 [==============================] - 69s 126ms/step - loss: 0.6437 - val_loss: 0.9214\n",
            "Epoch 55/1000\n",
            "549/549 [==============================] - 63s 115ms/step - loss: 0.6491 - val_loss: 0.6131\n",
            "Epoch 56/1000\n",
            "549/549 [==============================] - 76s 139ms/step - loss: 0.6384 - val_loss: 0.8996\n",
            "Epoch 57/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6437interval evaluation - epoch: 56 - explained variance: 0.183143\n",
            "549/549 [==============================] - 78s 142ms/step - loss: 0.6437 - val_loss: 1.4197\n",
            "Epoch 58/1000\n",
            "549/549 [==============================] - 67s 123ms/step - loss: 0.6411 - val_loss: 0.6263\n",
            "Epoch 59/1000\n",
            "549/549 [==============================] - 68s 125ms/step - loss: 0.6356 - val_loss: 0.6221\n",
            "Epoch 60/1000\n",
            "549/549 [==============================] - 68s 125ms/step - loss: 0.6368 - val_loss: 0.6115\n",
            "Epoch 61/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6417interval evaluation - epoch: 60 - explained variance: 0.319910\n",
            "549/549 [==============================] - 73s 134ms/step - loss: 0.6417 - val_loss: 2.1842\n",
            "Epoch 62/1000\n",
            "549/549 [==============================] - 76s 139ms/step - loss: 0.6409 - val_loss: 0.6093\n",
            "Epoch 63/1000\n",
            "549/549 [==============================] - 77s 140ms/step - loss: 0.6427 - val_loss: 0.7093\n",
            "Epoch 64/1000\n",
            "549/549 [==============================] - 72s 132ms/step - loss: 0.6473 - val_loss: 0.5830\n",
            "Epoch 65/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6320interval evaluation - epoch: 64 - explained variance: 0.389824\n",
            "549/549 [==============================] - 80s 145ms/step - loss: 0.6320 - val_loss: 0.6704\n",
            "Epoch 66/1000\n",
            "549/549 [==============================] - 78s 142ms/step - loss: 0.6309 - val_loss: 1.0668\n",
            "Epoch 67/1000\n",
            "549/549 [==============================] - 66s 119ms/step - loss: 0.6412 - val_loss: 0.6634\n",
            "Epoch 68/1000\n",
            "549/549 [==============================] - 68s 123ms/step - loss: 0.6429 - val_loss: 0.6035\n",
            "Epoch 69/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6337interval evaluation - epoch: 68 - explained variance: 0.367898\n",
            "549/549 [==============================] - 80s 146ms/step - loss: 0.6337 - val_loss: 0.6450\n",
            "Epoch 70/1000\n",
            "549/549 [==============================] - 80s 146ms/step - loss: 0.6303 - val_loss: 0.7582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = my_saluki.predict(X_val)\n",
        "print(\"Explained Var Score: %.2f\" % explained_variance_score(y_val, y_pred))\n",
        "print(\"R2 Score: %.2f\" % r2_score(y_val, y_pred))"
      ],
      "metadata": {
        "id": "7hCHlQnlWPVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43daaedf-4a68-404b-8146-d03887907fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 2s 37ms/step\n",
            "Explained Var Score: 0.39\n",
            "R2 Score: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_saluki.save('my_saluki5_21.h5')"
      ],
      "metadata": {
        "id": "RDHswe1X_W34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_loss(history):\n",
        "    fig, ax = plt.subplots(figsize = (5,5))\n",
        "    ax.plot(history['loss'][1:])\n",
        "    ax.plot(history['val_loss'][1:])\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('mean squared error')"
      ],
      "metadata": {
        "id": "5_Wi1QFKWEVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history.history)"
      ],
      "metadata": {
        "id": "KDZw8D75goko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "2166f07a-8315-4bed-9bc7-b2c1c3ba60d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lyycdEOWRAfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}