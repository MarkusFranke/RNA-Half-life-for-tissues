{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saluki v21 - Batchnorm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusFranke/RNA-Half-life-for-tissues/blob/main/models-for-general-half-life/Saluki_v21_Batchnorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKkQxNHexGtb"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO #for parsing Fasta Files\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from kipoiseq.transforms.functional import one_hot, fixed_len\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as k\n",
        "from keras.callbacks import EarlyStopping, History\n",
        "from keras.models import Model\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import keras.layers as kl\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can't run this in google colab due to RAM limitations, I'm importing the data from disk. All the data should be available on google drive though, under the same filenames, either to be downloaded and run with a path to where the user saved them, or to be directly accessible by mounting the google drive (and setting a shortcut to our google drive data path in google drive)\n"
      ],
      "metadata": {
        "id": "ku26rqE7x06J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hl = pd.read_excel(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\kelley_et_al_corrected_hl.xlsx', skiprows=[0, 1])\n",
        "hl['zscore'] = zscore(hl['half-life (PC1)'])\n",
        "halflife = hl[[\"Ensembl Gene Id\", \"zscore\"]]\n",
        "hl"
      ],
      "metadata": {
        "id": "7vRfq7bIxy4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "4fc013e6-9ce1-4dfa-8f41-010a2cfcfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ensembl Gene Id  Gene name  half-life (PC1)  Bazzini_ActD_HEK293_1  \\\n",
              "0      ENSG00000000003     TSPAN6         8.660955               0.763166   \n",
              "1      ENSG00000000419       DPM1         2.241221               0.529938   \n",
              "2      ENSG00000000457      SCYL3        -6.929173              -0.798471   \n",
              "3      ENSG00000000460   C1orf112         0.440909               0.461228   \n",
              "4      ENSG00000000938        FGR        -0.943680               0.164310   \n",
              "...                ...        ...              ...                    ...   \n",
              "13916  ENSG00000284770       TBCE         2.218664               0.100281   \n",
              "13917  ENSG00000285077  ARHGAP11B        -3.262964              -0.733980   \n",
              "13918  ENSG00000288596    C8orf44         2.118850              -0.485957   \n",
              "13919  ENSG00000288701     PRRC2B         0.133147               0.133770   \n",
              "13920  ENSG00000288722       F8A1        -3.485607              -0.607463   \n",
              "\n",
              "       Bazzini_ActD_HeLa_1  Bazzini_ActD_RPE_1  Bazzini_4sU_K562_1  \\\n",
              "0                 0.258448            0.106486            1.019072   \n",
              "1                 0.222678           -0.040666           -0.284952   \n",
              "2                -0.894854           -1.039150           -1.444532   \n",
              "3                 0.195794           -0.739672           -0.123925   \n",
              "4                 0.112064            0.095773            0.045345   \n",
              "...                    ...                 ...                 ...   \n",
              "13916            -0.187624           -0.143422            0.201024   \n",
              "13917            -0.934478           -0.952570           -0.461339   \n",
              "13918            -0.320560           -0.332189            0.582473   \n",
              "13919             0.214899            0.144491            0.090991   \n",
              "13920            -0.419258           -0.378650           -0.775774   \n",
              "\n",
              "       Akimitsu_BrU_HeLa_1  Rinn_ActD_K562_1  Rinn_ActD_K562_2  ...  \\\n",
              "0                 2.022504          1.744745          1.783356  ...   \n",
              "1                 0.145097          0.866919          0.832768  ...   \n",
              "2                -1.287191         -1.006317         -1.062201  ...   \n",
              "3                 0.162538         -0.023056         -0.008479  ...   \n",
              "4                 0.024136         -0.209157         -0.223700  ...   \n",
              "...                    ...               ...               ...  ...   \n",
              "13916             0.933352          0.465403          0.451758  ...   \n",
              "13917            -0.940048          0.225157          0.161858  ...   \n",
              "13918            -0.614775          0.305297          0.336730  ...   \n",
              "13919             0.131956         -0.040831         -0.035576  ...   \n",
              "13920             0.400149         -1.060379         -1.033201  ...   \n",
              "\n",
              "       Gejman_4sU_GM12812_1  Gejman_4sU_GM12814_1  Gejman_4sU_GM12815_1  \\\n",
              "0                  1.037361              0.969166              1.209562   \n",
              "1                 -0.212424             -0.747989              0.371214   \n",
              "2                 -1.155096             -1.421651             -1.568912   \n",
              "3                  1.365208              1.017193             -0.239569   \n",
              "4                  0.722198              1.024313              1.484018   \n",
              "...                     ...                   ...                   ...   \n",
              "13916              1.082013              0.917651              0.897480   \n",
              "13917              0.256969              0.033071             -0.249782   \n",
              "13918              1.023526             -0.155662             -0.950892   \n",
              "13919             -0.091563             -0.021327             -0.017414   \n",
              "13920              0.433892              0.446224              1.344124   \n",
              "\n",
              "       Simon_4sU_K562_1  Simon_4sU_K562_2  Rissland_4sU_HEK293_1  \\\n",
              "0              2.080643          2.095154               0.674058   \n",
              "1              0.772595          0.712843              -0.350914   \n",
              "2             -1.308978         -1.311572              -0.387172   \n",
              "3              0.373929          0.380154              -0.063720   \n",
              "4             -0.375671         -0.384504               0.232924   \n",
              "...                 ...               ...                    ...   \n",
              "13916          0.866792          0.868080              -0.104068   \n",
              "13917         -1.116405         -1.078302              -1.495412   \n",
              "13918         -0.175193         -0.166760               2.505294   \n",
              "13919          0.088581          0.107441               0.345123   \n",
              "13920         -0.631782         -0.629741              -0.413725   \n",
              "\n",
              "       Rissland_4sU_HEK293_2  Rissland_4sU_HEK293_3  Rissland_4sU_HEK293_4  \\\n",
              "0                   1.120375               1.456258               1.791769   \n",
              "1                  -0.879247              -0.825603               0.109861   \n",
              "2                  -1.229226              -1.122749              -0.570002   \n",
              "3                  -0.450610              -0.805719               0.453957   \n",
              "4                   0.347933               0.266619               0.063565   \n",
              "...                      ...                    ...                    ...   \n",
              "13916              -0.169414              -0.404886              -0.165188   \n",
              "13917              -1.006317              -1.240272              -1.440629   \n",
              "13918               1.068162               1.307039               1.563308   \n",
              "13919              -0.188176              -0.119128               0.001050   \n",
              "13920              -0.071227              -0.105036              -0.197549   \n",
              "\n",
              "         zscore  \n",
              "0      1.807620  \n",
              "1      0.467763  \n",
              "2     -1.446182  \n",
              "3      0.092022  \n",
              "4     -0.196955  \n",
              "...         ...  \n",
              "13916  0.463055  \n",
              "13917 -0.681011  \n",
              "13918  0.442223  \n",
              "13919  0.027789  \n",
              "13920 -0.727478  \n",
              "\n",
              "[13921 rows x 58 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ensembl Gene Id</th>\n",
              "      <th>Gene name</th>\n",
              "      <th>half-life (PC1)</th>\n",
              "      <th>Bazzini_ActD_HEK293_1</th>\n",
              "      <th>Bazzini_ActD_HeLa_1</th>\n",
              "      <th>Bazzini_ActD_RPE_1</th>\n",
              "      <th>Bazzini_4sU_K562_1</th>\n",
              "      <th>Akimitsu_BrU_HeLa_1</th>\n",
              "      <th>Rinn_ActD_K562_1</th>\n",
              "      <th>Rinn_ActD_K562_2</th>\n",
              "      <th>...</th>\n",
              "      <th>Gejman_4sU_GM12812_1</th>\n",
              "      <th>Gejman_4sU_GM12814_1</th>\n",
              "      <th>Gejman_4sU_GM12815_1</th>\n",
              "      <th>Simon_4sU_K562_1</th>\n",
              "      <th>Simon_4sU_K562_2</th>\n",
              "      <th>Rissland_4sU_HEK293_1</th>\n",
              "      <th>Rissland_4sU_HEK293_2</th>\n",
              "      <th>Rissland_4sU_HEK293_3</th>\n",
              "      <th>Rissland_4sU_HEK293_4</th>\n",
              "      <th>zscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>TSPAN6</td>\n",
              "      <td>8.660955</td>\n",
              "      <td>0.763166</td>\n",
              "      <td>0.258448</td>\n",
              "      <td>0.106486</td>\n",
              "      <td>1.019072</td>\n",
              "      <td>2.022504</td>\n",
              "      <td>1.744745</td>\n",
              "      <td>1.783356</td>\n",
              "      <td>...</td>\n",
              "      <td>1.037361</td>\n",
              "      <td>0.969166</td>\n",
              "      <td>1.209562</td>\n",
              "      <td>2.080643</td>\n",
              "      <td>2.095154</td>\n",
              "      <td>0.674058</td>\n",
              "      <td>1.120375</td>\n",
              "      <td>1.456258</td>\n",
              "      <td>1.791769</td>\n",
              "      <td>1.807620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000419</td>\n",
              "      <td>DPM1</td>\n",
              "      <td>2.241221</td>\n",
              "      <td>0.529938</td>\n",
              "      <td>0.222678</td>\n",
              "      <td>-0.040666</td>\n",
              "      <td>-0.284952</td>\n",
              "      <td>0.145097</td>\n",
              "      <td>0.866919</td>\n",
              "      <td>0.832768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.212424</td>\n",
              "      <td>-0.747989</td>\n",
              "      <td>0.371214</td>\n",
              "      <td>0.772595</td>\n",
              "      <td>0.712843</td>\n",
              "      <td>-0.350914</td>\n",
              "      <td>-0.879247</td>\n",
              "      <td>-0.825603</td>\n",
              "      <td>0.109861</td>\n",
              "      <td>0.467763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>SCYL3</td>\n",
              "      <td>-6.929173</td>\n",
              "      <td>-0.798471</td>\n",
              "      <td>-0.894854</td>\n",
              "      <td>-1.039150</td>\n",
              "      <td>-1.444532</td>\n",
              "      <td>-1.287191</td>\n",
              "      <td>-1.006317</td>\n",
              "      <td>-1.062201</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.155096</td>\n",
              "      <td>-1.421651</td>\n",
              "      <td>-1.568912</td>\n",
              "      <td>-1.308978</td>\n",
              "      <td>-1.311572</td>\n",
              "      <td>-0.387172</td>\n",
              "      <td>-1.229226</td>\n",
              "      <td>-1.122749</td>\n",
              "      <td>-0.570002</td>\n",
              "      <td>-1.446182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>C1orf112</td>\n",
              "      <td>0.440909</td>\n",
              "      <td>0.461228</td>\n",
              "      <td>0.195794</td>\n",
              "      <td>-0.739672</td>\n",
              "      <td>-0.123925</td>\n",
              "      <td>0.162538</td>\n",
              "      <td>-0.023056</td>\n",
              "      <td>-0.008479</td>\n",
              "      <td>...</td>\n",
              "      <td>1.365208</td>\n",
              "      <td>1.017193</td>\n",
              "      <td>-0.239569</td>\n",
              "      <td>0.373929</td>\n",
              "      <td>0.380154</td>\n",
              "      <td>-0.063720</td>\n",
              "      <td>-0.450610</td>\n",
              "      <td>-0.805719</td>\n",
              "      <td>0.453957</td>\n",
              "      <td>0.092022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>FGR</td>\n",
              "      <td>-0.943680</td>\n",
              "      <td>0.164310</td>\n",
              "      <td>0.112064</td>\n",
              "      <td>0.095773</td>\n",
              "      <td>0.045345</td>\n",
              "      <td>0.024136</td>\n",
              "      <td>-0.209157</td>\n",
              "      <td>-0.223700</td>\n",
              "      <td>...</td>\n",
              "      <td>0.722198</td>\n",
              "      <td>1.024313</td>\n",
              "      <td>1.484018</td>\n",
              "      <td>-0.375671</td>\n",
              "      <td>-0.384504</td>\n",
              "      <td>0.232924</td>\n",
              "      <td>0.347933</td>\n",
              "      <td>0.266619</td>\n",
              "      <td>0.063565</td>\n",
              "      <td>-0.196955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13916</th>\n",
              "      <td>ENSG00000284770</td>\n",
              "      <td>TBCE</td>\n",
              "      <td>2.218664</td>\n",
              "      <td>0.100281</td>\n",
              "      <td>-0.187624</td>\n",
              "      <td>-0.143422</td>\n",
              "      <td>0.201024</td>\n",
              "      <td>0.933352</td>\n",
              "      <td>0.465403</td>\n",
              "      <td>0.451758</td>\n",
              "      <td>...</td>\n",
              "      <td>1.082013</td>\n",
              "      <td>0.917651</td>\n",
              "      <td>0.897480</td>\n",
              "      <td>0.866792</td>\n",
              "      <td>0.868080</td>\n",
              "      <td>-0.104068</td>\n",
              "      <td>-0.169414</td>\n",
              "      <td>-0.404886</td>\n",
              "      <td>-0.165188</td>\n",
              "      <td>0.463055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13917</th>\n",
              "      <td>ENSG00000285077</td>\n",
              "      <td>ARHGAP11B</td>\n",
              "      <td>-3.262964</td>\n",
              "      <td>-0.733980</td>\n",
              "      <td>-0.934478</td>\n",
              "      <td>-0.952570</td>\n",
              "      <td>-0.461339</td>\n",
              "      <td>-0.940048</td>\n",
              "      <td>0.225157</td>\n",
              "      <td>0.161858</td>\n",
              "      <td>...</td>\n",
              "      <td>0.256969</td>\n",
              "      <td>0.033071</td>\n",
              "      <td>-0.249782</td>\n",
              "      <td>-1.116405</td>\n",
              "      <td>-1.078302</td>\n",
              "      <td>-1.495412</td>\n",
              "      <td>-1.006317</td>\n",
              "      <td>-1.240272</td>\n",
              "      <td>-1.440629</td>\n",
              "      <td>-0.681011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13918</th>\n",
              "      <td>ENSG00000288596</td>\n",
              "      <td>C8orf44</td>\n",
              "      <td>2.118850</td>\n",
              "      <td>-0.485957</td>\n",
              "      <td>-0.320560</td>\n",
              "      <td>-0.332189</td>\n",
              "      <td>0.582473</td>\n",
              "      <td>-0.614775</td>\n",
              "      <td>0.305297</td>\n",
              "      <td>0.336730</td>\n",
              "      <td>...</td>\n",
              "      <td>1.023526</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-0.950892</td>\n",
              "      <td>-0.175193</td>\n",
              "      <td>-0.166760</td>\n",
              "      <td>2.505294</td>\n",
              "      <td>1.068162</td>\n",
              "      <td>1.307039</td>\n",
              "      <td>1.563308</td>\n",
              "      <td>0.442223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13919</th>\n",
              "      <td>ENSG00000288701</td>\n",
              "      <td>PRRC2B</td>\n",
              "      <td>0.133147</td>\n",
              "      <td>0.133770</td>\n",
              "      <td>0.214899</td>\n",
              "      <td>0.144491</td>\n",
              "      <td>0.090991</td>\n",
              "      <td>0.131956</td>\n",
              "      <td>-0.040831</td>\n",
              "      <td>-0.035576</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.091563</td>\n",
              "      <td>-0.021327</td>\n",
              "      <td>-0.017414</td>\n",
              "      <td>0.088581</td>\n",
              "      <td>0.107441</td>\n",
              "      <td>0.345123</td>\n",
              "      <td>-0.188176</td>\n",
              "      <td>-0.119128</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.027789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13920</th>\n",
              "      <td>ENSG00000288722</td>\n",
              "      <td>F8A1</td>\n",
              "      <td>-3.485607</td>\n",
              "      <td>-0.607463</td>\n",
              "      <td>-0.419258</td>\n",
              "      <td>-0.378650</td>\n",
              "      <td>-0.775774</td>\n",
              "      <td>0.400149</td>\n",
              "      <td>-1.060379</td>\n",
              "      <td>-1.033201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.433892</td>\n",
              "      <td>0.446224</td>\n",
              "      <td>1.344124</td>\n",
              "      <td>-0.631782</td>\n",
              "      <td>-0.629741</td>\n",
              "      <td>-0.413725</td>\n",
              "      <td>-0.071227</td>\n",
              "      <td>-0.105036</td>\n",
              "      <td>-0.197549</td>\n",
              "      <td>-0.727478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13921 rows × 58 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.3pUTRs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    UTR3_identifiers = []\n",
        "    UTR3_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        UTR3_identifiers.append(seq_record.id)\n",
        "        UTR3_seqs.append(seq_record.seq)\n",
        "\n",
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.5pUTRs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    UTR5_identifiers = []\n",
        "    UTR5_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        UTR5_identifiers.append(seq_record.id)\n",
        "        UTR5_seqs.append(seq_record.seq)\n",
        "\n",
        "with open(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Homo_sapiens.GRCh38.83.chosenTranscript.ORFs.fa') as fasta_file:  # Will close handle cleanly\n",
        "    ORF_identifiers = []\n",
        "    ORF_seqs = []\n",
        "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
        "        ORF_identifiers.append(seq_record.id)\n",
        "        ORF_seqs.append(seq_record.seq)\n",
        "\n",
        "print(UTR3_seqs[0])\n",
        "print(UTR5_seqs[0])\n",
        "print(ORF_seqs[0])\n",
        "print(UTR3_identifiers[0])\n",
        "print(UTR5_identifiers[0])\n",
        "print(ORF_identifiers[0])\n",
        "print(len(UTR3_seqs))\n",
        "print(len(UTR5_seqs))\n",
        "print(len(ORF_seqs))"
      ],
      "metadata": {
        "id": "JFU1gCykz-M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f8bcb4-cb63-46be-d5c8-34683ac47b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AATATTATGTATGCAGCAATATTTGAGTAACAAGAAGCAAATATCCAAGTTCCAAAATTATAAAAGAAATTCTTATCCAAATAGTAATGTTCTAATTGATCATATAAGAAAGCAAAGCATAGACATTAGAATTATAAGTCAGCAGTGGTCTGTTCAAGAACAATCAACATTTTTAGAAAATAGTAGGACAAAATTAGGAAATAATTATCACCAAGAGGATCTAGTTCATGACTTTCTATTATCTCAATTAGATTGCTCAATCATCAGCCTTCCTATACTAAACTCTGATTCAGGACCAAGAAAGGCATAGTCTGACTCTGGAAATGCGCTGTTGGAAGCCAAATAACATCAATACTCTTGTTCTATAATTGAATATCAAATAAGACAAATTACCATTAATTTAATGACTGTGGAGTTAATTGTATACCAGCATTTCAGCAAATCATCATCAATAGTATTACATTAGCAATTTATGCAATTAAAAGGGCTTTGTAAAACTTTGAATAGATTTTATTGTCATTAGTAGCTGTTGGAACTTCATTATTATATAATGTTTTTGCAAACTTTAACTTTTTTCTAAATTGTTAAATAAAAGAATAACTATCCTTAATCTAAATAATTTTGGTAGCAAATCCTATAAGGTATTAAACATTTTAAGGTATATTATTACATTGCTATTTTACTGTTTCTCATTAACCCAAACAGTTTAAAGGCAGAATTCCACTTAGAAACAAGTTGCATTTTGAAAGTTTATTTGTAATCCATTTGTTTGGAATTCAGAAATGTATTTCACATAAAAATAATCTTGGAAGTAATAAATTCCAAAATTAACTAACAAAA\n",
            "AGATGAGATTTCATCATGTTGGCCAGCCTGGTCTCAAACTCCTGACCTCAAGTGACCCGCCTGCCTCAGCCTCCCAAAGTGCTGGGATTACAGGAATTTAGTGATTGACA\n",
            "ATGGCAGAAAAAATCCTAGAGAAGTTGGATGTCCTTGATAAGCAAGCAGAGATAATCTTGGCCAGAAGAACAAAGATAAACAGGCTTCAGAGTGAAGGAAGAAAAACAACTATGGCTATACCCCTGACATTTGATTTTCAGTTGGAATTTGAAGAAGCTCTTGCTACATCCGCGTCTAAGGCAATATCAAAGATCAAAGAAGACAAGTCATGCAGCATTACAAAATCAAAAATGCATGTCTCTTTCAAATGTGAGCCTGAACCTAGAAAGAGTAATTTTGAAAAGTCAAATTTAAGACCATTCTTTATTCAAACAAATGTAAAAAATAAAGAAAGTGAGTCAACAGCTCAAATTGAAAAAAAACCTAGGAAACCATTGGATTCTGTTGGTCTCTTAGAAGGTGATAGAAATAAAAGAAAAAAATCTCCACAGATGAACGATTTTAATATAAAAGAAAACAAATCGGTCAGAAATTATCAATTAAGTAAGTATAGGTCAGTAAGAAAGAAAAGCTTGCTCCCGTTGTGCTTTGAGGATGAATTGAAAAATCCACATGCCAAGATAGTCAACGTTAGTCCAACAAAGACAGTAACTTCTCACATGGAACAAAAGGACACAAATCCCATAATTTTCCATGACACAGAATATGTACGAATGTTACTTTTGACAAAAAATAGATTTTCTTCTCATCCTTTGGAAAATGAAAACATTTACCCACATAAAAGAACAAATTTCATTTTAGAAAGAAATTGTGAAATCCTCAAATCTATAATTGGCAATCAATCTATTTCTCTTTTCAAACCCCAAAAAACTATGCCTACAGTACAGAGAAAAGATATACAGATCCCTATGTCTTTTAAAGCGGGCCACACAACTGTAGATGATAAACTAAAGAAGAAAACTAATAAGCAGACACTAGAAAACAGATCTTGGAATACACTCTATAATTTCTCACAGAATTTTTCTAGCCTAACAAAACAATTTGTGGGTTACCTTGATAAAGCTGTTATTCATGAAATGAGTGCCCAAACTGGAAAATTTGAAAGAATGTTTTCTGCAGGAAAACCAACGAGCATACCCACATCCAGTGCCTTACCTGTCAAATGTTACTCAAAGCCTTTTAAATATATATATGAACTAAATAATGTAACGCCACTGGATAATTTGTTAAACTTATCAAATGAAATTTTAAATGCCTCA\n",
            "ENSG00000203963\n",
            "ENSG00000203963\n",
            "ENSG00000203963\n",
            "19094\n",
            "18642\n",
            "20253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exons = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Kelley_et_al_exon_junctions.txt', delimiter = \"\\t\")\n",
        "exons"
      ],
      "metadata": {
        "id": "HrhPuo0w0di6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2ed0e4f2-a716-4f52-ee8f-6556dec146f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                GeneID  UTR5_len  \\\n",
              "0      ENSG00000000003       112   \n",
              "1      ENSG00000000457       222   \n",
              "2      ENSG00000000460       700   \n",
              "3      ENSG00000000938       289   \n",
              "4      ENSG00000000971       240   \n",
              "...                ...       ...   \n",
              "13225  ENSG00000278615        48   \n",
              "13226  ENSG00000278619       239   \n",
              "13227  ENSG00000278845       161   \n",
              "13228  ENSG00000280789       574   \n",
              "13229  ENSG00000281991       330   \n",
              "\n",
              "                         Exon_Junctions_In_Full_Sequence  \n",
              "0                                199,388,463,562,697,781  \n",
              "1      387,573,687,744,847,959,1037,1177,1362,1534,16...  \n",
              "2      766,871,1012,1178,1263,1402,1483,1548,1697,182...  \n",
              "3           515,618,717,821,971,1127,1307,1384,1538,1670  \n",
              "4      298,484,590,667,859,1030,1204,1399,1576,1759,1...  \n",
              "...                                                  ...  \n",
              "13225                                         87,212,310  \n",
              "13226                                  781,875,1008,1128  \n",
              "13227                        227,405,523,622,671,821,995  \n",
              "13228                                          1056,1139  \n",
              "13229                                                495  \n",
              "\n",
              "[13230 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneID</th>\n",
              "      <th>UTR5_len</th>\n",
              "      <th>Exon_Junctions_In_Full_Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>112</td>\n",
              "      <td>199,388,463,562,697,781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>222</td>\n",
              "      <td>387,573,687,744,847,959,1037,1177,1362,1534,16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>700</td>\n",
              "      <td>766,871,1012,1178,1263,1402,1483,1548,1697,182...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>289</td>\n",
              "      <td>515,618,717,821,971,1127,1307,1384,1538,1670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000971</td>\n",
              "      <td>240</td>\n",
              "      <td>298,484,590,667,859,1030,1204,1399,1576,1759,1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13225</th>\n",
              "      <td>ENSG00000278615</td>\n",
              "      <td>48</td>\n",
              "      <td>87,212,310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13226</th>\n",
              "      <td>ENSG00000278619</td>\n",
              "      <td>239</td>\n",
              "      <td>781,875,1008,1128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13227</th>\n",
              "      <td>ENSG00000278845</td>\n",
              "      <td>161</td>\n",
              "      <td>227,405,523,622,671,821,995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13228</th>\n",
              "      <td>ENSG00000280789</td>\n",
              "      <td>574</td>\n",
              "      <td>1056,1139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13229</th>\n",
              "      <td>ENSG00000281991</td>\n",
              "      <td>330</td>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13230 rows × 3 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromosomes = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\Kelley_et_al_chromosomes.txt', delimiter = \"\\t\")\n",
        "chromosomes"
      ],
      "metadata": {
        "id": "N_zoThwx0u0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a1ddd771-86bb-4e2c-f689-d9236c341f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                GeneID  Chromosome\n",
              "0      ENSG00000186092           1\n",
              "1      ENSG00000279928           1\n",
              "2      ENSG00000279457           1\n",
              "3      ENSG00000278566           1\n",
              "4      ENSG00000273547           1\n",
              "...                ...         ...\n",
              "20290  ENSG00000277856  KI270726.1\n",
              "20291  ENSG00000275063  KI270726.1\n",
              "20292  ENSG00000271254  KI270711.1\n",
              "20293  ENSG00000277475  KI270713.1\n",
              "20294  ENSG00000268674  KI270713.1\n",
              "\n",
              "[20295 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeneID</th>\n",
              "      <th>Chromosome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000186092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000279928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000279457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000278566</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000273547</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20290</th>\n",
              "      <td>ENSG00000277856</td>\n",
              "      <td>KI270726.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20291</th>\n",
              "      <td>ENSG00000275063</td>\n",
              "      <td>KI270726.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20292</th>\n",
              "      <td>ENSG00000271254</td>\n",
              "      <td>KI270711.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20293</th>\n",
              "      <td>ENSG00000277475</td>\n",
              "      <td>KI270713.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20294</th>\n",
              "      <td>ENSG00000268674</td>\n",
              "      <td>KI270713.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20295 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromosomes['Chromosome'].value_counts()"
      ],
      "metadata": {
        "id": "i7fzASja1JI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8344b8c-5538-4c5a-f192-69830e25d225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1             2053\n",
              "19            1458\n",
              "11            1316\n",
              "2             1298\n",
              "17            1185\n",
              "3             1070\n",
              "6             1045\n",
              "12            1033\n",
              "7              980\n",
              "5              868\n",
              "16             865\n",
              "X              824\n",
              "14             824\n",
              "9              772\n",
              "4              747\n",
              "10             730\n",
              "8              670\n",
              "15             609\n",
              "20             541\n",
              "22             489\n",
              "13             320\n",
              "18             269\n",
              "21             233\n",
              "Y               54\n",
              "MT              13\n",
              "KI270728.1       6\n",
              "KI270727.1       4\n",
              "KI270734.1       3\n",
              "GL000194.1       2\n",
              "GL000195.1       2\n",
              "KI270726.1       2\n",
              "KI270713.1       2\n",
              "GL000009.2       1\n",
              "GL000205.2       1\n",
              "GL000219.1       1\n",
              "GL000213.1       1\n",
              "GL000218.1       1\n",
              "KI270731.1       1\n",
              "KI270721.1       1\n",
              "KI270711.1       1\n",
              "Name: Chromosome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XRaMXVFv1YvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbp_k = np.load(r'C:\\Users\\marku\\Desktop\\ML4RG_shared_with_students\\Saluki_Data\\RBP_k.npy')\n",
        "rbp_k.shape"
      ],
      "metadata": {
        "id": "pNwe4p0T4_u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af35a693-667a-4eeb-ca7c-6a7da4361d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13230, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So not only do we have much more chromosomes, we the data comes from Pedro (df), Saluki (the sequences), from Pauline (chromosomes, exon junctions, via Saluki-chosen transcript), and from Yasmine (RBPs using Deepripe).\n",
        "Thus we should take good care that we merge the tables correctly."
      ],
      "metadata": {
        "id": "ITVKHQAf5c5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'geneID': UTR5_identifiers, 'UTR5_seqs': UTR5_seqs}\n",
        "UTR5 = pd.DataFrame(data=d)\n",
        "d = {'geneID': ORF_identifiers, 'ORF_seqs': ORF_seqs}\n",
        "ORF = pd.DataFrame(data=d)\n",
        "d = {'geneID': UTR3_identifiers, 'UTR3_seqs': UTR3_seqs}\n",
        "UTR3 = pd.DataFrame(data=d)\n",
        "\n",
        "#merge every data frame to sequences\n",
        "halflife = hl[[\"Ensembl Gene Id\", \"zscore\"]] # half-life\n",
        "seqs = pd.merge(pd.merge(UTR5, ORF, on ='geneID'), UTR3, on = 'geneID') # Sequence\n",
        "sequences = pd.merge(halflife, seqs, right_on = 'geneID', left_on = 'Ensembl Gene Id') # half-life + Sequence\n",
        "sequences = sequences.drop(columns=[\"geneID\"])\n",
        "sequences = sequences.rename(columns={\"Ensembl Gene Id\": \"geneID\"})\n",
        "sequences = pd.merge(sequences, chromosomes, left_on='geneID', right_on='GeneID') # halflife + Sequence + chromosomes\n",
        "sequences = sequences.drop(columns=[\"GeneID\"])\n",
        "sequences = pd.merge(sequences, exons, left_on='geneID', right_on='GeneID')# halflife + Sequence + chromosomes + exons\n",
        "sequences = sequences.drop(columns=[\"GeneID\"])\n",
        "\n",
        "#transform seqs into strings:\n",
        "sequences[\"UTR5_seqs\"] = sequences[\"UTR5_seqs\"].apply(str)\n",
        "sequences[\"UTR3_seqs\"] = sequences[\"UTR3_seqs\"].apply(str)\n",
        "sequences[\"ORF_seqs\"] = sequences[\"ORF_seqs\"].apply(str)\n",
        "\n",
        "rubbish = [d, UTR3, ORF, UTR5, UTR5_seqs, UTR3_seqs, ORF_seqs, UTR3_identifiers, UTR5_identifiers, ORF_identifiers, hl, halflife]\n",
        "del rubbish\n",
        "\n",
        "sequences.head()"
      ],
      "metadata": {
        "id": "M7rLipk85dwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "12c48f21-156b-4650-9997-813ee6880bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            geneID    zscore  \\\n",
              "0  ENSG00000000003  1.807620   \n",
              "1  ENSG00000000457 -1.446182   \n",
              "2  ENSG00000000460  0.092022   \n",
              "3  ENSG00000000938 -0.196955   \n",
              "4  ENSG00000000971  1.611324   \n",
              "\n",
              "                                           UTR5_seqs  \\\n",
              "0  AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGG...   \n",
              "1  TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCC...   \n",
              "2  GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTT...   \n",
              "3  GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCC...   \n",
              "4  ACAGCATTAACATTTAGTGGGAGTGCAGTGAGAATTGGGTTTAACT...   \n",
              "\n",
              "                                            ORF_seqs  \\\n",
              "0  ATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTT...   \n",
              "1  ATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAAC...   \n",
              "2  ATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCT...   \n",
              "3  ATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCA...   \n",
              "4  ATGAGACTTCTAGCAAAGATTATTTGCCTTATGTTATGGGCTATTT...   \n",
              "\n",
              "                                           UTR3_seqs Chromosome  UTR5_len  \\\n",
              "0  CCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTT...          X       112   \n",
              "1  CAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTA...          1       222   \n",
              "2  AACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAA...          1       700   \n",
              "3  CCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGC...          1       289   \n",
              "4  AATCAATCATAAAGTGCACACCTTTATTCAGAACTTTAGTATTAAA...          1       240   \n",
              "\n",
              "                     Exon_Junctions_In_Full_Sequence  \n",
              "0                            199,388,463,562,697,781  \n",
              "1  387,573,687,744,847,959,1037,1177,1362,1534,16...  \n",
              "2  766,871,1012,1178,1263,1402,1483,1548,1697,182...  \n",
              "3       515,618,717,821,971,1127,1307,1384,1538,1670  \n",
              "4  298,484,590,667,859,1030,1204,1399,1576,1759,1...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geneID</th>\n",
              "      <th>zscore</th>\n",
              "      <th>UTR5_seqs</th>\n",
              "      <th>ORF_seqs</th>\n",
              "      <th>UTR3_seqs</th>\n",
              "      <th>Chromosome</th>\n",
              "      <th>UTR5_len</th>\n",
              "      <th>Exon_Junctions_In_Full_Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENSG00000000003</td>\n",
              "      <td>1.807620</td>\n",
              "      <td>AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGG...</td>\n",
              "      <td>ATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTT...</td>\n",
              "      <td>CCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTT...</td>\n",
              "      <td>X</td>\n",
              "      <td>112</td>\n",
              "      <td>199,388,463,562,697,781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENSG00000000457</td>\n",
              "      <td>-1.446182</td>\n",
              "      <td>TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCC...</td>\n",
              "      <td>ATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAAC...</td>\n",
              "      <td>CAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTA...</td>\n",
              "      <td>1</td>\n",
              "      <td>222</td>\n",
              "      <td>387,573,687,744,847,959,1037,1177,1362,1534,16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENSG00000000460</td>\n",
              "      <td>0.092022</td>\n",
              "      <td>GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTT...</td>\n",
              "      <td>ATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCT...</td>\n",
              "      <td>AACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>700</td>\n",
              "      <td>766,871,1012,1178,1263,1402,1483,1548,1697,182...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENSG00000000938</td>\n",
              "      <td>-0.196955</td>\n",
              "      <td>GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCC...</td>\n",
              "      <td>ATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCA...</td>\n",
              "      <td>CCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGC...</td>\n",
              "      <td>1</td>\n",
              "      <td>289</td>\n",
              "      <td>515,618,717,821,971,1127,1307,1384,1538,1670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENSG00000000971</td>\n",
              "      <td>1.611324</td>\n",
              "      <td>ACAGCATTAACATTTAGTGGGAGTGCAGTGAGAATTGGGTTTAACT...</td>\n",
              "      <td>ATGAGACTTCTAGCAAAGATTATTTGCCTTATGTTATGGGCTATTT...</td>\n",
              "      <td>AATCAATCATAAAGTGCACACCTTTATTCAGAACTTTAGTATTAAA...</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>298,484,590,667,859,1030,1204,1399,1576,1759,1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 10000 #this is slightly longer than the 95% quantile, but lower than Saluki's implementation\n",
        "\n",
        "seqs = sequences['UTR5_seqs'] + sequences['ORF_seqs'] + sequences['UTR3_seqs']\n",
        "def pad_sequence(seqs, max_len, anchor='start', value='N'):\n",
        "  padded_seqs = [fixed_len(seq, max_len, anchor=anchor) for seq in seqs.astype(\"string\")]\n",
        "  return padded_seqs\n",
        "fixed_len_seqs = np.array(pad_sequence(seqs, max_len))\n",
        "print(fixed_len_seqs[0:4])\n",
        "del seqs\n",
        "print(fixed_len_seqs.shape)"
      ],
      "metadata": {
        "id": "y8oUTj9w-XQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cbaa5c-81b9-4114-9efb-526899e3e577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AGTTGTGGACGCTCGTAAGTTTTCGGCAGTTTCCGGGGAGACTCGGGGACTCCGCGTCTCGCTCTCTGTGTTCCAATCGCCCGGTGCGGTGGTGCAGGGTCTCGGGCTAGTCATGGCGTCCCCGTCTCGGAGACTGCAGACTAAACCAGTCATTACTTGTTTCAAGAGCGTTCTGCTAATCTACACTTTTATTTTCTGGATCACTGGCGTTATCCTTCTTGCAGTTGGCATTTGGGGCAAGGTGAGCCTGGAGAATTACTTTTCTCTTTTAAATGAGAAGGCCACCAATGTCCCCTTCGTGCTCATTGCTACTGGTACCGTCATTATTCTTTTGGGCACCTTTGGTTGTTTTGCTACCTGCCGAGCTTCTGCATGGATGCTAAAACTGTATGCAATGTTTCTGACTCTCGTTTTTTTGGTCGAACTGGTCGCTGCCATCGTAGGATTTGTTTTCAGACATGAGATTAAGAACAGCTTTAAGAATAATTATGAGAAGGCTTTGAAGCAGTATAACTCTACAGGAGATTATAGAAGCCATGCAGTAGACAAGATCCAAAATACGTTGCATTGTTGTGGTGTCACCGATTATAGAGATTGGACAGATACTAATTATTACTCAGAAAAAGGATTTCCTAAGAGTTGCTGTAAACTTGAAGATTGTACTCCACAGAGAGATGCAGACAAAGTAAACAATGAAGGTTGTTTTATAAAGGTGATGACCATTATAGAGTCAGAAATGGGAGTCGTTGCAGGAATTTCCTTTGGAGTTGCTTGCTTCCAACTGATTGGAATCTTTCTCGCCTACTGCCTCTCTCGTGCCATAACAAATAACCAGTATGAGATAGTGCCCAATGTATCTGTGGGCCTATTCCTCTCTACCTTTAAGGACATTTAGGGTCCCCCCTGTGAATTAGAAAGTTGCTTGGCTGGAGAACTGACAACACTACTTACTGATAGACCAAAAAACTACACCAGTAGGTTGATTCAATCAAGATGTATGTAGACCTAAAACTACACCAATAGGCTGATTCAATCAAGATCCGTGCTCGCAGTGGGCTGATTCAATCAAGATGTATGTTTGCTATGTTCTAAGTCCACCTTCTATCCCATTCATGTTAGATCGTTGAAACCCTGTATCCCTCTGAAACACTGGAAGAGCTAGTAAATTGTAAATGAAGTAATACTGTGTTCCTCTTGACTGTTATTTTTCTTAGTAGGGGGCCTTTGGAAGGCACTGTGAATTTGCTATTTTGATGTAGTGTTACAAGATGGAAAATTGATTCCTCTGACTTTGCTATTGATGTAGTGTGATAGAAAATTCACCCCTCTGAACTGGCTCCTTCCCAGTCAAGGTTATCTGGTTTGATTGTATAATTTGCACCAAGAAGTTAAAATGTTTTATGACTCTCTGTTCTGCTGACAGGCAGAGAGTCACATTGTGTAATTTAATTTCAGTCAGTCAATAGATGGCATCCCTCATCAGGGTTGCCAGATGGTGATAACAGTGTAAGGCCTTGGGTCTAAGGCATCCACGACTGGAAGGGACTACTGATGTTCTGTGATACATCAGGTTTCAGCACACAACTTACATTTCTTTGCCTCCAAATTGAGGCATTTATTATGATGTTCATACTTTCCCTCTTGTTTGAAAGTTTCTAATTATTAAATGGTGTCGGAATTGTTGTATTTTCCTTAGGAATTCAGTGGAACTTATCTTCATTAAATTTAGCTGGTACCAGGTTGATATGACTTGTCAATATTATGGTCAACTTTAAGTCTTAGTTTTCGTTTGTGCCTTTGATTAATAAGTATAACTCTTATACAATAAATACTGCTTTCCTCTAAAAAGATCGTGTTTAAATTAACTTGTAGAAAATCTGCTGGAATGGTTGTTGTTTTCCACTGAGAAAGCTAAGCCCTACATTTCTATTCAGAGTACTGTTTTTAGATGTGAAATATAAGCCTGCGGCCTTAACTCTGTATTAAAAAAAATGTTTTTGTTTAAAAAAAACTGTTCCCATAGGTGCAGCAAACCACCATGGCACATGTATACCTATGTAACAAACCTGCACATTCTGCACATGTATCCCAGAACTTAATGTAAACAAAAAAATCTTAAAGTGCAAATATTAAAAAAAACTGTTCTCTGTGAAAAAAATTATATTCCATGTTATAAAGTAGCATATGACTAGTGTTCTCCTAGNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'TGTCCCGTTTCCGGACCCGTCTCTATGGTGTAGGAGAAACCCGGCCCCCAGAAGATTGTGGGTGTAGTGGCCACAGCCTTACAGGCAGGCAGGGGTGGTTGGTGTCAACAGGGGGGCCAACAGGGTACCAGAGCCAAGACCCTCGGCCTCCTCCCCCGCCGCCTTCCTGCAGATCTGCTTGGCTTTGAGGAAGAGTGGCAGTACTGCCTCACTGCATAAGGGATGGGATCAGAGAACAGTGCTTTAAAGAGCTATACACTGAGAGAACCACCATTTACCTTACCCTCTGGACTTGCTGTTTATCCCGCTGTACTGCAAGATGGCAAATTTGCTTCAGTTTTTGTGTATAAGAGAGAAAATGAAGACAAGGTTAATAAAGCTGCCAAGCATTTGAAGACACTTCGTCACCCTTGCTTGCTAAGATTTTTATCTTGTACTGTGGAAGCGGATGGCATTCATCTTGTCACTGAGCGAGTACAGCCCCTGGAAGTGGCTTTGGAAACATTGTCTTCTGCAGAGGTCTGTGCTGGGATCTATGACATATTGCTGGCTCTTATCTTCCTTCATGACAGAGGACACCTAACACACAATAATGTCTGTTTATCATCTGTGTTTGTGAGTGAAGATGGACACTGGAAGCTAGGAGGAATGGAAACTGTTTGTAAAGTTTCTCAGGCCACACCAGAGTTTCTGAGGAGTATTCAGTCAATAAGAGACCCAGCATCTATCCCTCCTGAAGAGATGTCTCCAGAATTCACAACTCTCCCAGAGTGTCATGGACATGCCCGGGATGCCTTTTCATTTGGAACATTGGTGGAAAGTTTGCTCACAATCTTAAATGAACAGGTTTCAGCGGATGTTCTCTCCAGCTTTCAACAGACCTTGCACTCAACTTTGCTGAATCCCATTCCAAAATGTCGGCCAGCGCTCTGCACCTTACTATCTCATGACTTCTTCAGAAATGATTTTCTGGAAGTTGTGAATTTCTTGAAAAGTTTAACATTGAAGAGTGAAGAGGAGAAAACGGAATTCTTTAAATTTCTGCTGGACAGAGTCAGCTGCTTGTCAGAGGAATTGATAGCTTCAAGGTTGGTGCCTCTTCTGCTTAATCAGTTGGTGTTTGCAGAGCCAGTGGCTGTTAAGAGTTTTCTTCCTTATCTGCTTGGCCCCAAAAAAGATCATGCGCAGGGAGAAACTCCTTGCTTGCTCTCACCAGCCCTGTTCCAGTCACGGGTGATCCCCGTGCTTCTCCAGTTGTTTGAAGTTCATGAAGAGCATGTGCGGATGGTGCTGCTGTCTCACATCGAGGCCTACGTGGAGCACTTCACTCAGGAGCAGCTGAAGAAAGTCATCTTGCCACAGGTTTTGCTGGGCCTGCGTGATACTAGCGATTCCATTGTGGCAATTACTCTGCATAGCCTAGCAGTGCTGGTCTCTCTGCTTGGACCAGAGGTGGTTGTGGGAGGAGAACGAACCAAGATCTTCAAACGCACTGCCCCAAGTTTTACTAAAAATACTGACCTTTCTCTAGAAGATTCTCCTATGTGTGTCGTCTGCAGCCATCACAGTCAGATCTCGCCAATCTTGGAGAACCCCTTCTCTAGCATATTCCCTAAATGTTTCTTTTCTGGCAGCACGCCCATCAACAGCAAGAAGCACATACAGCGAGATTACTACAATACTCTTTTACAGACAGGCGATCCATTTTCTCAGCCTATTAAATTTCCCATAAATGGACTCTCAGATGTAAAAAATACTTCGGAGGACAGTGAAAACTTCCCATCAAGTTCTAAAAAGTCTGAGGAGTGGCCTGACTGGAGTGAACCTGAGGAGCCTGAAAATCAAACTGTCAACATACAGATTTGGCCTAGAGAACCTTGTGATGATGTCAAGTCCCAGTGCACTACCTTGGATGTGGAAGAGTCATCTTGGGATGACTGCGAGCCCAGCAGCTTAGATACTAAAGTAAACCCAGGAGGTGGAATCACTGCTACAAAACCTGTTACCTCAGGGGAGCAGAAGCCTATTCCTGCTTTGCTTTCACTCACTGAAGAGTCTATGCCTTGGAAATCAAGCTTACCCCAAAAGATTAGCCTTGTACAAAGGGGGGATGACGCAGACCAAATCGAGCCGCCAAAAGTGTCATCACAAGAAAGGCCCCTTAAGGTTCCATCAGAACTTGGTTTAGGAGAGGAATTCACCATTCAAGTAAAAAAGAAGCCAGTAAAAGATCCTGAGATGGATTGGTTTGCTGATATGATCCCAGAAATTAAGCCTTCTGCTGCTTTTCTTATATTACCTGAACTGAGGACAGAAATGGTCCCAAAAAAGGATGATGTCTCCCCAGTGATGCAGTTTTCCTCAAAATTTGCTGCAGCAGAAATTACTGAGGGAGAGGCTGAAGGCTGGGAAGAAGAAGGGGAGCTGAACTGGGAAGATAATAACTGGCAATAGATGTGAGTTAAACTTTAGGAAAAAGGATTCCCTTTTTTTAAAAAAAATCAATACCTCAAAAGCAGGCTTTGGGACAAGAAAACCCCAAAGTGGCCTGCTTTTCCCATCCCAGGAGCTCATTATCCAGTCTGTGCCAACTGAAGTAGGAGACTGACTGTGAGTGCTGGCTAAAAGCCCTGGGTGGTGAGGCTCACAGTACTGGTTTCCAGGAGGAAGAGCCTTTGTGCATTTGACTGAGGCCAGTTTCTATGAAGAGCAAGTAGCTGAGGAGAGGTCGAATTTACTGCTTTTTCCAGGACAATTCTGGAAGTAAAGAAAATGTAATTCAAGCTGGTTAGCTTAATTTTGTGCCATTCTTTAACATAAGAGTAAGCTCTATTATGAAATACAACTTTAAAAAATTTTAGCTATAAATTATATAAATGATTTTAAATTGCTGAGGTTTCCTTAGGCAGCTTATTTATTTGTTTACAGTTAGACTATCTGAGTAAATGGTTCTTTGTGGACCTAGGCAGTTCCTGACTGTTCCACATGTAGTACATTGTACCAAAGTTCTTAATAAGAATATTCCCCACAATCCTGTTCTCTAAATGTCAAATAAAGATTATTTTCACTAGATTCAACTTTACAAAANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'GGCTTTGGCCCTGGAAAGCCTCGCGGACGTGTTCTGACCCAAGGTTTTAGCAGTGGATGTGGCGTTTTCTTCCATTCCTTCTTTCAGTTTTTCTGTACTCGTTGCTTGCAATTAAGTGTAAATACTTTTGCTAGTGGATAATGGGGGAGGCAAGGACTGAGACCTGCGGTATGACGATAGCTCTGGCTCTTAATAGTTTGAGGTAAAGCGAGATACTCTGAGCTTTTGTCTCCCGTAAAAAGGGTGGTGAATATGAATAAGGGCTTTCTTAGCGTTATAAGAATTAAAGGGCATAGTTCTGTGGTGTGAAATCTTTAAAAGATGTTCAGTAAATAAAAATGATTTTCCTCCTTCCCCTCTCAGACCTCTTTTTCTTCTTTCTTTCTTTTTTTTTGACAAGTTCTCACTCCTCTCACCCAGGCTGGAGTCTTTCTGAAAGAGTTCTTCCGCTTGTTGTTGGCTTTCAACTGTTGGATTTGAGGCGCTTAGCGCCTTCTTCGTCCGGGTGCAGCACATTCTTGATTGGTCTCATGCCTTTGTGGTTGTAAATGTGCCTGGAATCCTAGCCTTTCATGGTTTGTTCTGAGTAATGAATACCCTATTACTATGATACTAGTATCTTCCTTAATTATCCTACTCATTGTCTCAACATTCTGACAGTTGGATTGAGCATATTCAAATTTTGAAAATTATTGTAGAAATGTTTTTACCTCATATGAACCACCTGACATTGGAACAGACTTTCTTTTCACAAGTGTTACCAAAGACTGTGAAATTATTCGATGACATGATGTATGAATTAACCAGTCAAGCCAGAGGACTGTCAAGCCAAAATTTGGAAATCCAGACCACTCTAAGGAATATTTTACAAACAATGGTGCAGCTCTTAGGAGCTCTCACAGGATGTGTTCAGCATATCTGTGCCACACAGGAATCCATCATTTTGGAAAATATTCAGAGTCTCCCCTCCTCAGTCCTTCATATAATTAAAAGCACATTTGTGCATTGTAAGAATAGTGAATCTGTGTATTCTGGGTGTTTACACCTAGTTTCAGACCTTCTCCAGGCTCTTTTCAAGGAGGCCTATTCTCTTCAAAAGCAGTTAATGGAACTGCTGGACATGGTTTGCATGGACCCTTTAGTAGATGACAATGATGATATTTTGAATATGGTAATAGTTATTCATTCTTTATTGGATATCTGCTCTGTTATTTCCAGTATGGACCATGCATTTCATGCCAATACTTGGAAGTTTATAATTAAGCAGAGCCTTAAGCACCAGTCCATAATAAAAAGCCAGTTGAAACACAAAGATATAATTACTAGCTTGTGTGAAGACATTCTTTTCTCCTTCCATTCTTGTTTACAGTTAGCTGAGCAGATGACACAGTCAGATGCACAGGATAATGCTGACTACAGATTATTTCAGAAAACACTCAAATTGTGTCGTTTTTTTGCCAACTCCCTTTTGCACTACGCTAAGGAATTTCTTCCTTTCCTCTCTGATTCTTGCTGTACTTTGCACCAACTGTATCTTCAGATACACAGCAAGTTTCCTCCAAGCCTTTATGCTACCAGGATTTCTAAAGCACACCAAGAGGAAATAGCAGGTGCTTTCCTAGTGACACTGGATCCACTTATCAGTCAGCTGCTCACATTTCAGCCTTTCATGCAGGTGGTTTTGGACAGTAAATTAGACCTGCCATGTGAACTGCAGTTTCCACAATGTCTTCTTCTGGTTGTTGTCATGGATAAGCTGCCATCTCAGCCTAAGGAAGTGCAAACCCTGTGGTGCACAGACAGCCAGGTCTCAGAAACGACAACCAGGATATCTCTACTCAAAGCCGTTTTCTACAGTTTTGAGCAGTGTTCTGGTGAACTCTCTCTACCTGTTCATTTACAGGGATTAAAGAGTAAGGGGAAAGCTGAGGTGGCTGTCACCTTGTATCAGCATGTTTGTGTTCATCTGTGTACATTTATTACTTCCTTTCATCCCTCACTGTTTGCTGAACTGGATGCTGCTCTGCTGAATGCTGTACTTAGTGCTAATATGATCACCTCTTTGTTAGCTATGGATGCATGGTGCTTCCTTGCTCGATATGGGACTGCTGAACTGTGTGCACACCATGTCACCATAGTGGCTCATCTGATAAAGTCATGCCCTGGAGAATGTTATCAACTCATCAACCTATCAATACTGTTGAAGCGTCTCTTTTTCTTCATGGCACCACCCCATCAGCTGGAGTTTATCCAGAAATTTTCCCCAAAAGAAGCAGAAAATCTGCCTCTGTGGCAACATATTTCCTTCCAGGCGTTACCTCCTGAGCTTAGGGAACAAACTGTCCATGAGGTCACCACAGTAGGCACTGCAGAATGCAGGAAATGGCTGAGCAGGAGTCGTACTTTGGGAGAACTAGAATCTCTGAACACAGTACTGTCTGCTTTGCTTGCAGTATGTAATTCTGCTGGTGAAGCTTTGGATACAGGAAAACAAACTGCAATTATCGAAGTTGTGAGTCAGCTTTGGGCTTTTTTAAACATTAAACAGGTAGCAGATCAACCTTATGTTCAACAGACATTCAGCCTTTTACTTCCACTGTTGGGATTTTTCATTCAAACTCTAGATCCTAAACTGATACTTCAGGCAGTAACTTTGCAGACCTCGCTACTTAAATTAGAGCTTCCTGACTATGTTCGTTTGGCAATGTTGGATTTTGTATCTTCTTTAGGAAAACTTTTTATACCTGAAGCTATCCAGGACAGAATTCTGCCCAACCTGTCCTGTATGTTTGCCTTACTGCTAGCTGACAGGAGTTGGCTGCTAGAACAACATACCTTGGAGGCGTTTACTCAGTTCGCTGAGGGAACAAATCATGAAGAGATAGTTCCACAGTGTCTCAGTTCTGAAGAAACTAAGAACAAAGTTGTATCCTTTCTGGAGAAGACTGGGTTTGTAGATGAAACTGAAGCTGCCAAAGTGGAACGTGTGAAACAGGAAAAAGGTATTTTCTGGGAACCCTTTGCTAATGTGACTGTAGAAGAAGCAAAGAGGTCATCTTTACAGCCTTATGCAAAAAGAGCTCGTCAGGAGTTCCCCTGGGAAGAAGAGTACAGGTCAGCGCTGCATACAATAGCAGGGGCTTTGGAAGCAACTGAGTCACTACTCCAAAAGGGTCCTGCTCCAGCCTGGCTTTCAATGGAAATGGAGGCGCTCCAAGAAAGGATGGATAAGCTAAAACGTTACATACATACTCTAGGGAACTTATCACTAGGCAGAACTGGGTTTGATGCTTTGTCAACTGAAAATACTTATGTCTGTACATTTTCTAACAGATATAAAACAAATTTTGTAAAGTTGAATCTAGTGAAAATAATCTTTATTTGACATTTAGAGAACAGGATTGTGGGGAATATTCTTATTAAGAACTTTGGTACAATGTACTACATGTGGAACAGTCAGGAACTGCCTAGGTCCACAAAGAACCATTTACTCAGATAGTCTAACTGTAAACAAATAAATAAGCTGCCTAAGGAAACCTCAGCAATTTAAAATCATTTATATAATTTATAGCTAAAATTTTTTAAAGTTGTATTTCATAATAGAGCTTACTCTTATGTTAAAGAATGGCACAAAATTAAGCTAACCAGCTTGAATTACATTTTCTTTACTTCCAGAATTGTCCTGGAAAAAGCAGTAAATTCGACCTCTCCTCAGCTACTTGCTCTTCATAGAAACTGGCCTCAGTCAAATGCACAAAGGCTCTTCCTCCTGGAAACCAGTACTGTGAGCCTCACCACCCAGGGCTTTTAGCCAGCACTCACAGTCAGTCTCCTACTTCAGTTGGCACAGACTGGATAATGAGCTCCTGGGATGGGAAAAGCAGGCCACTTTGGGGTTTTCTTGTCCCAAAGCCTGCTTTTGAGGTATTGATTTTTTTTAAAAAAAGGGAATCCTTTTTCCTAAAGTTTAACTCACATCTATTGTCACCAGTTATTATCTTCCCAGTTCAGCTCCCCTTCTTCTTCCCAGCCTTCAGCCTCTCCCTGCAACAAAATAAAGCACACCAAGAACCCACTGAAACAAATCATATGCAAAAATCATACGCAAATTTGAAAAAGCAGGAATTTAAAATTTATCTTTTGATGCCAGAAACACTACCTCGTACTAAGTAAAATAACTTAGAGCTCTAACAGAAAGTTGAAAAGTAGGATTACAAAACCATGGCACTGGAAAATAGCTTTTCAAAAACCATAAAATCCAGTAAAAATCAGTGTGGATGACACCAAATCCTTATTTTAATCCCTTTTTTTTCTTTTTCAAATAAAAAGGTTACAATAGCTCATTAAACAAANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN'\n",
            " 'GGCTTGGGGCTAGGGCGTGACTGTCTCCCTGCCACCATCACCGCCCGCCGGCCGTGACTGCAATAAGAGAAGTCCGAGGCGGCTTCCTCCTCCCTGCCCAGCAGGGGCGGCGGTCAGAGGCGGGCAGCACCCCAGTTCTCCCCGCACGCCGGCACTCGCGGCTGCTGGAGCCCCGGCTGGCTCACCCCGGGGCCGGGCAGAATTGGGCTCCAGGTCTCTGACCCCTCCCAAGGATCATGCCGCAGCCCCACTGACCCAGGAGTAGGGGCCTAAGGGCAGGGAACCTGGAATGGGCTGTGTGTTCTGCAAGAAATTGGAGCCGGTGGCCACGGCCAAGGAGGATGCTGGCCTGGAAGGGGACTTCAGAAGCTACGGGGCAGCAGACCACTATGGGCCTGACCCCACTAAGGCCCGGCCTGCATCCTCATTTGCCCACATCCCCAACTACAGCAACTTCTCCTCTCAGGCCATCAACCCTGGCTTCCTTGATAGTGGCACCATCAGGGGTGTGTCAGGGATTGGGGTGACCCTGTTCATTGCCCTGTATGACTATGAGGCTCGAACTGAGGATGACCTCACCTTCACCAAGGGCGAGAAGTTCCACATCCTGAACAATACTGAAGGTGACTGGTGGGAGGCTCGGTCTCTCAGCTCCGGAAAAACTGGCTGCATTCCCAGCAACTACGTGGCCCCTGTTGACTCAATCCAAGCTGAAGAGTGGTACTTTGGAAAGATTGGGAGAAAGGATGCAGAGAGGCAGCTGCTTTCACCAGGCAACCCCCAGGGGGCCTTTCTCATTCGGGAAAGCGAGACCACCAAAGGTGCCTACTCCCTGTCCATCCGGGACTGGGATCAGACCAGAGGCGATCATGTGAAGCATTACAAGATCCGCAAACTGGACATGGGCGGCTACTACATCACCACACGGGTTCAGTTCAACTCGGTGCAGGAGCTGGTGCAGCACTACATGGAGGTGAATGACGGGCTGTGCAACCTGCTCATCGCGCCCTGCACCATCATGAAGCCGCAGACGCTGGGCCTGGCCAAGGACGCCTGGGAGATCAGCCGCAGCTCCATCACGCTGGAGCGCCGGCTGGGCACCGGCTGCTTCGGGGATGTGTGGCTGGGCACGTGGAACGGCAGCACTAAGGTGGCGGTGAAGACGCTGAAGCCGGGCACCATGTCCCCGAAGGCCTTCCTGGAGGAGGCGCAGGTCATGAAGCTGCTGCGGCACGACAAGCTGGTGCAGCTGTACGCCGTGGTGTCGGAGGAGCCCATCTACATCGTGACCGAGTTCATGTGTCACGGCAGCTTGCTGGATTTTCTCAAGAACCCAGAGGGCCAGGATTTGAGGCTGCCCCAATTGGTGGACATGGCAGCCCAGGTAGCTGAGGGCATGGCCTACATGGAACGCATGAACTACATTCACCGCGACCTGAGGGCAGCCAACATCCTGGTTGGGGAGCGGCTGGCGTGCAAGATCGCAGACTTTGGCTTGGCGCGTCTCATCAAGGACGATGAGTACAACCCCTGCCAAGGTTCCAAGTTCCCCATCAAGTGGACAGCCCCAGAAGCTGCCCTCTTTGGCAGATTCACCATCAAGTCAGACGTGTGGTCCTTTGGGATCCTGCTCACTGAGCTCATCACCAAGGGCCGAATCCCCTACCCAGGCATGAATAAACGGGAAGTGTTGGAACAGGTGGAGCAGGGCTACCACATGCCGTGCCCTCCAGGCTGCCCAGCATCCCTGTACGAGGCCATGGAACAGACCTGGCGTCTGGACCCGGAGGAGAGGCCTACCTTCGAGTACCTGCAGTCCTTCCTGGAGGACTACTTCACCTCCGCTGAACCACAGTACCAGCCCGGGGATCAGACACCTGTCCGGGCATCAACCCTCTCTGGCGGTGGCCACCAGTCCTTGCCAATCCCCAGAGCTGTTCTTCCAAAGCCCCCAGGCTGGCTTAGAACCCCATAGAGTCCTAGCATCACCGAGGACGTGGCTGCTCTGACACCACCTAGGGCAACCTACTTGTTTTACAGATGGGGCAAAAGGAGGCCCAGAGCTGATCTCTCATCCGCTCTGGCCCCAAGCACTATTTCTTCCTTTTCCACTTAGGCCCCTACATGCCTGTAGCCTTTCTCACTCCATCCCCACCCAAAGTGCTCAGACCTTGTCTAGTTATTTATAAAACTGTATGTACCTCCCTCACTTCTCTCCTATCACTGCTTTCCTACTCTCCTTTTATCTCACTCTAGTCCAGGTGCCAAGAATTTCCCTTCTACCCTCTATTCTCTTGTGTCTGTAAGTTACAAAGTCAGGAAAAGTCTTGGCTGGACCCCTTTCCTGCTGGGTGGATGCAGTGGTCCAGGACTGGGGTCTGGGCCCAGGTTTGAGGGAGAAGGTTGCAGAGCACTTCCCACCTCTCTGAATAGTGTGTATGTGTTGGTTTATTGATTCTGTAAATAAGTAAAATGACAATATGAATCCTCAAACCATGAAATACCCTTGAACCTTCCTTTGGGAGCGGGGGTGGTCAATAGGGGGTGAACGGACAGATATGGCTACAGGCAGCAGCAGGGGAAGCTGGAGAGGGCCCTAATGCCTACCAAGCACGGGGCATCCAAGGTGTGGAGTTTTAGAACACCCAGAGTCCCACTGCTCATCTGCACGTGAGTTTAGAAGACAAGCAGCTGAAGATACATTAAAATGTCCCCTTCGTTGCTGANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN']\n",
            "(13230,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot for track 1-4: the nucleotides \n",
        "\n",
        "one_hot_seqs = np.array([one_hot(seq, neutral_value=0) for seq in fixed_len_seqs])\n",
        "print(one_hot_seqs[0:2])\n",
        "print(one_hot_seqs.shape)\n",
        "rubbish = [fixed_len_seqs] \n",
        "del rubbish"
      ],
      "metadata": {
        "id": "PdyuPKVL_0QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d39ace-6f37-4668-d94d-f0d2923d8e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]]\n",
            "(13230, 10000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot for track 5: the exon binding sites\n",
        "# dunno why, I guess I still suck at python, but this took me over an hours to code and bugfix\n",
        "# lol this is future me from the next day, this was wrong and I had redo all the training\n",
        "\n",
        "exons = []\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  onehot = np.repeat(0, repeats = max_len)\n",
        "  if(isinstance(sequences[\"Exon_Junctions_In_Full_Sequence\"][i], str)):\n",
        "    current_exons = list(map(int, sequences[\"Exon_Junctions_In_Full_Sequence\"][i].split(\",\")))\n",
        "    assert len(current_exons) > 0\n",
        "    positions_capped = [x for x in current_exons if x <= 10000] # delete all exon junctions after 10000 since we're capping the sequence there\n",
        "    onehot[positions_capped] = 1\n",
        "    '''\n",
        "    for j in current_exons:\n",
        "      positions = [x+len(sequences['UTR5_seqs'][i]) for x in current_exons] # have to add UTR5 length to indices\n",
        "      positions_capped = [x for x in positions if x <= 10000] # delete all exon junctions after 10000 since we're capping the sequence there\n",
        "      onehot[positions_capped] = 1 #exon junctions are 1 now\n",
        "      \n",
        "  if(isinstance(sequences[\"Exon_Junctions_In_Full_Sequence\"][i], float)):\n",
        "    if(not(math.isnan(sequences[\"Exon_Junctions_In_Full_Sequence\"][i]))):\n",
        "      onehot[int(sequences[\"Exon_Junctions_In_Full_Sequence\"][i])+len(sequences['UTR5_seqs'][i])] = 1\n",
        "    '''\n",
        "  exons.append(onehot)"
      ],
      "metadata": {
        "id": "27vK8R2SAD9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(map(int, sequences[\"Exon_Junctions_In_Full_Sequence\"][5].split(\",\"))))"
      ],
      "metadata": {
        "id": "VDsHa06rCEQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37626c27-1fa5-4e03-d533-54036c8d1a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[280, 468, 808, 1019, 1210, 1319]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot for track 6: Marking the beginning of each codon with 1\n",
        "starts = []\n",
        "for i in range(len(sequences)):\n",
        "  #assert len(sequences['ORF_seqs'].astype(\"string\")[i]) % 3 == 0 \n",
        "  lst = list(range(len(sequences['ORF_seqs'].astype(\"string\")[i])))\n",
        "  onehot = np.repeat(0, repeats = len(sequences['ORF_seqs'].astype(\"string\")[i]))\n",
        "  onehot[lst[0::3]] = 1\n",
        "  full = np.concatenate((np.repeat([0], repeats = len(sequences['UTR5_seqs'].astype(\"string\")[i])),\n",
        "                         onehot,\n",
        "                         np.repeat([0], repeats = len(sequences['UTR3_seqs'].astype(\"string\")[i]))), axis=None)\n",
        "  if (len(full) > max_len):\n",
        "    full = full[:max_len]\n",
        "  elif (len(full) < max_len):\n",
        "    full = np.concatenate((full, np.repeat(0, repeats = max_len - len(full))),axis = None)\n",
        "  starts.append(full)"
      ],
      "metadata": {
        "id": "pRuNTsz4AHLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rubbish = [fixed_len_seqs]\n",
        "\n",
        "rubbish = [fixed_len_seqs, d, UTR3, ORF, UTR5, UTR5_seqs, UTR3_seqs, ORF_seqs, hl,\n",
        "           UTR3_identifiers, UTR5_identifiers, ORF_identifiers, halflife, max_len]\n",
        "del rubbish"
      ],
      "metadata": {
        "id": "lt-QVEBiP5Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes about 18 GB, so beware of that\n",
        "onehot = np.concatenate((one_hot_seqs,np.array(exons)[:, :, None], np.array(starts)[:, :, None]), axis = 2)\n",
        "print(onehot.shape)"
      ],
      "metadata": {
        "id": "6ZpZoaGuPp3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93688eb4-a0e1-417f-f4ba-7f137953d294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13230, 10000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del exons\n",
        "del starts"
      ],
      "metadata": {
        "id": "8qpC7Tr5RZae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for The Train-Val-Test split we split as recommended on Chromosomes:"
      ],
      "metadata": {
        "id": "oM3U9VTxSy0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chrom_val = ['2', '3', '4']\n",
        "chrom_test = ['1', '8', '9']"
      ],
      "metadata": {
        "id": "Ih4OOJxISyJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_test = np.where(sequences.Chromosome.isin(chrom_test))[0]\n",
        "idx_val = np.where(sequences.Chromosome.isin(chrom_val))[0]\n",
        "idx_train = np.where(~(sequences.Chromosome.isin(chrom_test)| sequences.Chromosome.isin(chrom_val)))[0]"
      ],
      "metadata": {
        "id": "FQcQCI4BTFSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(array, idx_train, idx_val, idx_test):\n",
        "  return array[idx_train], array[idx_val], array[idx_test]"
      ],
      "metadata": {
        "id": "k7GWuUtuTJxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(idx_test))\n",
        "print(len(idx_val))\n",
        "print(len(idx_train))"
      ],
      "metadata": {
        "id": "aOrm43s0Z8M2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4cc1c1-80f1-4cbe-c1f6-1d52ef0af105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2334\n",
            "2118\n",
            "8778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = train_test_split(onehot, idx_train, idx_val, idx_test)\n",
        "y_train, y_val, y_test = train_test_split(sequences['zscore'].values, idx_train, idx_val, idx_test)"
      ],
      "metadata": {
        "id": "mmpWExHRTfMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplainedVariance(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=10):\n",
        "        super(keras.callbacks.Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            var_score = explained_variance_score(self.y_val, y_pred)\n",
        "            #r2 = r2_score(self.y_val, y_pred)\n",
        "            del y_pred\n",
        "            #print(\" - interval evaluation - epoch: {:d} - explained variance: {:.6f} - R2: {:.6f}\".format(epoch, var_score, r2))\n",
        "            print(\"interval evaluation - epoch: {:d} - explained variance: {:.6f}\".format(epoch, var_score))\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "xf5ZZA63U-qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saluki-Type model\n",
        "input = kl.Input((X_train.shape[1:]))\n",
        "\n",
        "x = kl.Conv1D(64, kernel_size=5, activation=None, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(input)\n",
        "x = kl.BatchNormalization()(x)\n",
        "x = kl.Activation(\"relu\")(x)\n",
        "x = kl.Dropout(0.3)(x)\n",
        "\n",
        "for i in range(6):\n",
        "  x = kl.Conv1D(64, kernel_size=5, activation=None, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(x)\n",
        "  x = kl.MaxPooling1D(pool_size=2)(x)\n",
        "  x = kl.BatchNormalization()(x)\n",
        "  x = kl.Activation(\"relu\")(x)\n",
        "  x = kl.Dropout(0.3)(x)\n",
        "\n",
        "x = kl.GRU(64, go_backwards=True, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(x)\n",
        "x = kl.BatchNormalization()(x)\n",
        "x = kl.Activation(\"relu\")(x)\n",
        "x = kl.Dropout(0.3)(x)\n",
        "\n",
        "x = kl.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(l=0.0005))(x) #backwards so it encounters padding first\n",
        "x = kl.Activation(\"relu\")(x)\n",
        "\n",
        "output = kl.Dense(units=1)(x)\n",
        "\n",
        "my_saluki = Model(inputs=input, outputs=output)\n",
        "my_saluki.summary()\n",
        "\n",
        "#Saluki: We chose layer normalization over batch normalization because most of the 3′ positions are zero padded and would confuse the batch statistics.\n"
      ],
      "metadata": {
        "id": "X0vIgaHIVpyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64339a5e-4603-42d8-b8db-58f6b7f3cd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 10000, 6)]        0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 9996, 64)          1984      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 9996, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 9996, 64)          0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9996, 64)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 9992, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 4996, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4996, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4996, 64)          0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4996, 64)          0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 4992, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2496, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 2496, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2496, 64)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2496, 64)          0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 2492, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 1246, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1246, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1246, 64)          0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1246, 64)          0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 1242, 64)          20544     \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 621, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 621, 64)          256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 621, 64)           0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 621, 64)           0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 617, 64)           20544     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 308, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 308, 64)          256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 308, 64)           0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 308, 64)           0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 304, 64)           20544     \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 152, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 152, 64)          256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 152, 64)           0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 152, 64)           0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,705\n",
            "Trainable params: 159,681\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "hUAbPQFOV3mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18022770-9497-4992-a3e7-a719f1c43e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import datetime"
      ],
      "metadata": {
        "id": "aIP6jd9lV5o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So my GPU-memory is somewhat unstable and prone to error for batchsize bigger than 16, yet\n",
        "# batch size 16 works fine if I restart everything for every model.fit"
      ],
      "metadata": {
        "id": "mo9tczmEapVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "my_saluki.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.98, clipnorm=0.5),\n",
        "              loss=\"mse\")\n",
        "\n",
        "logdir = os.path.join(os.path.join(os.getcwd(), \"logs\"), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "# Train the model\n",
        "history = my_saluki.fit(X_train, y_train,\n",
        "                        #X_train[0:200,:], y_train[0:200], \n",
        "                        validation_data=(X_val, y_val),  \n",
        "                        #validation_data=(X_val[0:100,:], y_val[0:100]),\n",
        "                        callbacks=[EarlyStopping(patience=25, restore_best_weights=True),   \n",
        "                                   History(),\n",
        "                                   ExplainedVariance(validation_data=(X_val, y_val), interval=4),\n",
        "                                   tensorboard_callback],\n",
        "                        batch_size=16,  #they used 64\n",
        "                        shuffle = True,\n",
        "                        epochs=1000)  "
      ],
      "metadata": {
        "id": "t13N24J-V8eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7a2832-f550-4521-c423-d98747fd2ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 1.6050interval evaluation - epoch: 0 - explained variance: -0.020271\n",
            "549/549 [==============================] - 36s 49ms/step - loss: 1.6050 - val_loss: 1.4060\n",
            "Epoch 2/1000\n",
            "549/549 [==============================] - 22s 40ms/step - loss: 1.3018 - val_loss: 1.4153\n",
            "Epoch 3/1000\n",
            "549/549 [==============================] - 23s 42ms/step - loss: 1.0024 - val_loss: 1.3755\n",
            "Epoch 4/1000\n",
            "549/549 [==============================] - 25s 46ms/step - loss: 0.8694 - val_loss: 0.7982\n",
            "Epoch 5/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.8244interval evaluation - epoch: 4 - explained variance: 0.157322\n",
            "549/549 [==============================] - 29s 52ms/step - loss: 0.8244 - val_loss: 1.0015\n",
            "Epoch 6/1000\n",
            "549/549 [==============================] - 27s 50ms/step - loss: 0.7858 - val_loss: 0.6936\n",
            "Epoch 7/1000\n",
            "549/549 [==============================] - 35s 63ms/step - loss: 0.7619 - val_loss: 1.1899\n",
            "Epoch 8/1000\n",
            "549/549 [==============================] - 34s 62ms/step - loss: 0.7344 - val_loss: 0.9689\n",
            "Epoch 9/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.7299interval evaluation - epoch: 8 - explained variance: 0.357927\n",
            "549/549 [==============================] - 44s 80ms/step - loss: 0.7299 - val_loss: 0.6573\n",
            "Epoch 10/1000\n",
            "549/549 [==============================] - 42s 76ms/step - loss: 0.7160 - val_loss: 0.8792\n",
            "Epoch 11/1000\n",
            "549/549 [==============================] - 46s 83ms/step - loss: 0.7148 - val_loss: 2.1072\n",
            "Epoch 12/1000\n",
            "549/549 [==============================] - 55s 99ms/step - loss: 0.7072 - val_loss: 0.6985\n",
            "Epoch 13/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6938interval evaluation - epoch: 12 - explained variance: 0.390606\n",
            "549/549 [==============================] - 54s 98ms/step - loss: 0.6938 - val_loss: 0.6124\n",
            "Epoch 14/1000\n",
            "549/549 [==============================] - 67s 122ms/step - loss: 0.6862 - val_loss: 1.0075\n",
            "Epoch 15/1000\n",
            "549/549 [==============================] - 50s 91ms/step - loss: 0.6853 - val_loss: 0.6358\n",
            "Epoch 16/1000\n",
            "549/549 [==============================] - 61s 110ms/step - loss: 0.6837 - val_loss: 0.8298\n",
            "Epoch 17/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6862interval evaluation - epoch: 16 - explained variance: 0.385255\n",
            "549/549 [==============================] - 57s 104ms/step - loss: 0.6862 - val_loss: 0.6938\n",
            "Epoch 18/1000\n",
            "549/549 [==============================] - 61s 111ms/step - loss: 0.6817 - val_loss: 0.6441\n",
            "Epoch 19/1000\n",
            "549/549 [==============================] - 56s 102ms/step - loss: 0.6833 - val_loss: 0.9899\n",
            "Epoch 20/1000\n",
            "549/549 [==============================] - 56s 103ms/step - loss: 0.6707 - val_loss: 0.8348\n",
            "Epoch 21/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.6777interval evaluation - epoch: 20 - explained variance: 0.385011\n",
            "549/549 [==============================] - 60s 110ms/step - loss: 0.6781 - val_loss: 1.0007\n",
            "Epoch 22/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6846 - val_loss: 1.0644\n",
            "Epoch 23/1000\n",
            "549/549 [==============================] - 70s 128ms/step - loss: 0.6849 - val_loss: 0.6378\n",
            "Epoch 24/1000\n",
            "549/549 [==============================] - 78s 143ms/step - loss: 0.6664 - val_loss: 0.6765\n",
            "Epoch 25/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6579interval evaluation - epoch: 24 - explained variance: 0.350918\n",
            "549/549 [==============================] - 80s 146ms/step - loss: 0.6579 - val_loss: 1.6087\n",
            "Epoch 26/1000\n",
            "549/549 [==============================] - 72s 131ms/step - loss: 0.6673 - val_loss: 0.9228\n",
            "Epoch 27/1000\n",
            "549/549 [==============================] - 62s 114ms/step - loss: 0.6685 - val_loss: 0.6000\n",
            "Epoch 28/1000\n",
            "549/549 [==============================] - 49s 90ms/step - loss: 0.6696 - val_loss: 0.5863\n",
            "Epoch 29/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6664interval evaluation - epoch: 28 - explained variance: 0.319079\n",
            "549/549 [==============================] - 61s 111ms/step - loss: 0.6664 - val_loss: 1.4994\n",
            "Epoch 30/1000\n",
            "549/549 [==============================] - 57s 104ms/step - loss: 0.6695 - val_loss: 0.6187\n",
            "Epoch 31/1000\n",
            "549/549 [==============================] - 55s 101ms/step - loss: 0.6594 - val_loss: 0.8943\n",
            "Epoch 32/1000\n",
            "549/549 [==============================] - 59s 107ms/step - loss: 0.6593 - val_loss: 0.7444\n",
            "Epoch 33/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6550interval evaluation - epoch: 32 - explained variance: 0.397940\n",
            "549/549 [==============================] - 64s 116ms/step - loss: 0.6550 - val_loss: 0.6858\n",
            "Epoch 34/1000\n",
            "549/549 [==============================] - 56s 102ms/step - loss: 0.6517 - val_loss: 0.5829\n",
            "Epoch 35/1000\n",
            "549/549 [==============================] - 66s 121ms/step - loss: 0.6543 - val_loss: 0.5995\n",
            "Epoch 36/1000\n",
            "549/549 [==============================] - 66s 121ms/step - loss: 0.6623 - val_loss: 0.7004\n",
            "Epoch 37/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6556interval evaluation - epoch: 36 - explained variance: 0.339880\n",
            "549/549 [==============================] - 53s 96ms/step - loss: 0.6556 - val_loss: 1.3024\n",
            "Epoch 38/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6560 - val_loss: 0.5770\n",
            "Epoch 39/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6590 - val_loss: 0.5961\n",
            "Epoch 40/1000\n",
            "549/549 [==============================] - 58s 105ms/step - loss: 0.6568 - val_loss: 0.6052\n",
            "Epoch 41/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6657interval evaluation - epoch: 40 - explained variance: 0.392722\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6657 - val_loss: 0.6495\n",
            "Epoch 42/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6549 - val_loss: 0.8693\n",
            "Epoch 43/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6450 - val_loss: 0.5953\n",
            "Epoch 44/1000\n",
            "549/549 [==============================] - 45s 83ms/step - loss: 0.6440 - val_loss: 0.6922\n",
            "Epoch 45/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6533interval evaluation - epoch: 44 - explained variance: 0.412395\n",
            "549/549 [==============================] - 57s 103ms/step - loss: 0.6533 - val_loss: 0.5932\n",
            "Epoch 46/1000\n",
            "549/549 [==============================] - 52s 95ms/step - loss: 0.6492 - val_loss: 0.6076\n",
            "Epoch 47/1000\n",
            "549/549 [==============================] - 52s 94ms/step - loss: 0.6484 - val_loss: 0.5978\n",
            "Epoch 48/1000\n",
            "549/549 [==============================] - 52s 96ms/step - loss: 0.6459 - val_loss: 0.5866\n",
            "Epoch 49/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6424interval evaluation - epoch: 48 - explained variance: 0.401491\n",
            "549/549 [==============================] - 54s 98ms/step - loss: 0.6424 - val_loss: 0.7630\n",
            "Epoch 50/1000\n",
            "549/549 [==============================] - 61s 111ms/step - loss: 0.6400 - val_loss: 0.5957\n",
            "Epoch 51/1000\n",
            "549/549 [==============================] - 44s 80ms/step - loss: 0.6387 - val_loss: 0.5769\n",
            "Epoch 52/1000\n",
            "549/549 [==============================] - 45s 82ms/step - loss: 0.6383 - val_loss: 0.6132\n",
            "Epoch 53/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6320interval evaluation - epoch: 52 - explained variance: 0.420219\n",
            "549/549 [==============================] - 60s 109ms/step - loss: 0.6320 - val_loss: 0.5769\n",
            "Epoch 54/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6353 - val_loss: 0.6161\n",
            "Epoch 55/1000\n",
            "549/549 [==============================] - 49s 90ms/step - loss: 0.6364 - val_loss: 0.6389\n",
            "Epoch 56/1000\n",
            "549/549 [==============================] - 45s 82ms/step - loss: 0.6344 - val_loss: 0.7224\n",
            "Epoch 57/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6442interval evaluation - epoch: 56 - explained variance: 0.407029\n",
            "549/549 [==============================] - 57s 105ms/step - loss: 0.6442 - val_loss: 0.7874\n",
            "Epoch 58/1000\n",
            "549/549 [==============================] - 57s 104ms/step - loss: 0.6328 - val_loss: 0.7355\n",
            "Epoch 59/1000\n",
            "549/549 [==============================] - 48s 87ms/step - loss: 0.6322 - val_loss: 0.7716\n",
            "Epoch 60/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6204 - val_loss: 0.9395\n",
            "Epoch 61/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6297interval evaluation - epoch: 60 - explained variance: 0.411677\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6297 - val_loss: 0.5803\n",
            "Epoch 62/1000\n",
            "549/549 [==============================] - 52s 94ms/step - loss: 0.6331 - val_loss: 0.5802\n",
            "Epoch 63/1000\n",
            "549/549 [==============================] - 52s 94ms/step - loss: 0.6319 - val_loss: 0.5875\n",
            "Epoch 64/1000\n",
            "549/549 [==============================] - 48s 87ms/step - loss: 0.6320 - val_loss: 1.2421\n",
            "Epoch 65/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6371interval evaluation - epoch: 64 - explained variance: 0.417974\n",
            "549/549 [==============================] - 47s 86ms/step - loss: 0.6371 - val_loss: 0.6271\n",
            "Epoch 66/1000\n",
            "549/549 [==============================] - 47s 85ms/step - loss: 0.6324 - val_loss: 0.9266\n",
            "Epoch 67/1000\n",
            "549/549 [==============================] - 47s 86ms/step - loss: 0.6332 - val_loss: 0.6529\n",
            "Epoch 68/1000\n",
            "549/549 [==============================] - 47s 86ms/step - loss: 0.6221 - val_loss: 0.6122\n",
            "Epoch 69/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6292interval evaluation - epoch: 68 - explained variance: 0.394852\n",
            "549/549 [==============================] - 50s 91ms/step - loss: 0.6292 - val_loss: 0.6505\n",
            "Epoch 70/1000\n",
            "549/549 [==============================] - 53s 96ms/step - loss: 0.6272 - val_loss: 0.7301\n",
            "Epoch 71/1000\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6311 - val_loss: 0.6057\n",
            "Epoch 72/1000\n",
            "549/549 [==============================] - 47s 85ms/step - loss: 0.6257 - val_loss: 0.5752\n",
            "Epoch 73/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6297interval evaluation - epoch: 72 - explained variance: 0.412501\n",
            "549/549 [==============================] - 50s 92ms/step - loss: 0.6297 - val_loss: 0.6067\n",
            "Epoch 74/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6298 - val_loss: 0.6719\n",
            "Epoch 75/1000\n",
            "549/549 [==============================] - 53s 96ms/step - loss: 0.6296 - val_loss: 0.5706\n",
            "Epoch 76/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6253 - val_loss: 0.6914\n",
            "Epoch 77/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6255interval evaluation - epoch: 76 - explained variance: 0.383057\n",
            "549/549 [==============================] - 52s 96ms/step - loss: 0.6255 - val_loss: 1.0141\n",
            "Epoch 78/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6228 - val_loss: 0.6519\n",
            "Epoch 79/1000\n",
            "549/549 [==============================] - 45s 82ms/step - loss: 0.6266 - val_loss: 0.5922\n",
            "Epoch 80/1000\n",
            "549/549 [==============================] - 44s 80ms/step - loss: 0.6234 - val_loss: 0.8970\n",
            "Epoch 81/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6265interval evaluation - epoch: 80 - explained variance: 0.384727\n",
            "549/549 [==============================] - 65s 118ms/step - loss: 0.6265 - val_loss: 0.5965\n",
            "Epoch 82/1000\n",
            "549/549 [==============================] - 53s 97ms/step - loss: 0.6255 - val_loss: 0.6159\n",
            "Epoch 83/1000\n",
            "549/549 [==============================] - 59s 107ms/step - loss: 0.6207 - val_loss: 0.5686\n",
            "Epoch 84/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6227 - val_loss: 0.5845\n",
            "Epoch 85/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6188interval evaluation - epoch: 84 - explained variance: 0.413788\n",
            "549/549 [==============================] - 53s 96ms/step - loss: 0.6188 - val_loss: 0.6440\n",
            "Epoch 86/1000\n",
            "549/549 [==============================] - 50s 91ms/step - loss: 0.6258 - val_loss: 0.9154\n",
            "Epoch 87/1000\n",
            "549/549 [==============================] - 44s 80ms/step - loss: 0.6227 - val_loss: 0.6156\n",
            "Epoch 88/1000\n",
            "549/549 [==============================] - 47s 86ms/step - loss: 0.6242 - val_loss: 0.8667\n",
            "Epoch 89/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6213interval evaluation - epoch: 88 - explained variance: 0.431920\n",
            "549/549 [==============================] - 57s 104ms/step - loss: 0.6213 - val_loss: 0.6577\n",
            "Epoch 90/1000\n",
            "549/549 [==============================] - 46s 83ms/step - loss: 0.6141 - val_loss: 0.5650\n",
            "Epoch 91/1000\n",
            "549/549 [==============================] - 48s 88ms/step - loss: 0.6151 - val_loss: 0.5891\n",
            "Epoch 92/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6077 - val_loss: 0.6432\n",
            "Epoch 93/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6207interval evaluation - epoch: 92 - explained variance: 0.418126\n",
            "549/549 [==============================] - 49s 90ms/step - loss: 0.6207 - val_loss: 0.6205\n",
            "Epoch 94/1000\n",
            "549/549 [==============================] - 46s 83ms/step - loss: 0.6153 - val_loss: 1.7095\n",
            "Epoch 95/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6247 - val_loss: 0.7884\n",
            "Epoch 96/1000\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6116 - val_loss: 0.6483\n",
            "Epoch 97/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6198interval evaluation - epoch: 96 - explained variance: 0.401329\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6198 - val_loss: 0.7037\n",
            "Epoch 98/1000\n",
            "549/549 [==============================] - 45s 81ms/step - loss: 0.6193 - val_loss: 0.5816\n",
            "Epoch 99/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6155 - val_loss: 0.7430\n",
            "Epoch 100/1000\n",
            "549/549 [==============================] - 51s 92ms/step - loss: 0.6149 - val_loss: 0.6124\n",
            "Epoch 101/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6111interval evaluation - epoch: 100 - explained variance: 0.402986\n",
            "549/549 [==============================] - 75s 136ms/step - loss: 0.6111 - val_loss: 0.7457\n",
            "Epoch 102/1000\n",
            "549/549 [==============================] - 53s 96ms/step - loss: 0.6070 - val_loss: 0.5652\n",
            "Epoch 103/1000\n",
            "549/549 [==============================] - 63s 115ms/step - loss: 0.6177 - val_loss: 0.5829\n",
            "Epoch 104/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6160 - val_loss: 0.5830\n",
            "Epoch 105/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6153interval evaluation - epoch: 104 - explained variance: 0.409233\n",
            "549/549 [==============================] - 66s 121ms/step - loss: 0.6153 - val_loss: 0.6656\n",
            "Epoch 106/1000\n",
            "549/549 [==============================] - 52s 96ms/step - loss: 0.6154 - val_loss: 0.5784\n",
            "Epoch 107/1000\n",
            "549/549 [==============================] - 58s 105ms/step - loss: 0.6133 - val_loss: 0.5638\n",
            "Epoch 108/1000\n",
            "549/549 [==============================] - 54s 98ms/step - loss: 0.6266 - val_loss: 1.0136\n",
            "Epoch 109/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6213interval evaluation - epoch: 108 - explained variance: 0.406715\n",
            "549/549 [==============================] - 56s 103ms/step - loss: 0.6213 - val_loss: 0.5947\n",
            "Epoch 110/1000\n",
            "549/549 [==============================] - 50s 92ms/step - loss: 0.6190 - val_loss: 0.6373\n",
            "Epoch 111/1000\n",
            "549/549 [==============================] - 43s 78ms/step - loss: 0.6188 - val_loss: 0.5833\n",
            "Epoch 112/1000\n",
            "549/549 [==============================] - 48s 88ms/step - loss: 0.6079 - val_loss: 0.7039\n",
            "Epoch 113/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6222interval evaluation - epoch: 112 - explained variance: 0.418399\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6222 - val_loss: 0.6464\n",
            "Epoch 114/1000\n",
            "549/549 [==============================] - 51s 92ms/step - loss: 0.6168 - val_loss: 0.5974\n",
            "Epoch 115/1000\n",
            "549/549 [==============================] - 48s 88ms/step - loss: 0.6076 - val_loss: 0.6611\n",
            "Epoch 116/1000\n",
            "549/549 [==============================] - 42s 76ms/step - loss: 0.6127 - val_loss: 1.0308\n",
            "Epoch 117/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6167interval evaluation - epoch: 116 - explained variance: 0.421142\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6167 - val_loss: 0.5734\n",
            "Epoch 118/1000\n",
            "549/549 [==============================] - 61s 111ms/step - loss: 0.6042 - val_loss: 0.5769\n",
            "Epoch 119/1000\n",
            "549/549 [==============================] - 58s 106ms/step - loss: 0.6064 - val_loss: 0.6162\n",
            "Epoch 120/1000\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6104 - val_loss: 0.5908\n",
            "Epoch 121/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6089interval evaluation - epoch: 120 - explained variance: 0.415687\n",
            "549/549 [==============================] - 57s 104ms/step - loss: 0.6089 - val_loss: 0.7337\n",
            "Epoch 122/1000\n",
            "549/549 [==============================] - 67s 122ms/step - loss: 0.6125 - val_loss: 0.7358\n",
            "Epoch 123/1000\n",
            "549/549 [==============================] - 64s 117ms/step - loss: 0.6128 - val_loss: 0.5729\n",
            "Epoch 124/1000\n",
            "549/549 [==============================] - 59s 108ms/step - loss: 0.6087 - val_loss: 0.6516\n",
            "Epoch 125/1000\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.6096interval evaluation - epoch: 124 - explained variance: 0.407417\n",
            "549/549 [==============================] - 51s 93ms/step - loss: 0.6097 - val_loss: 0.6268\n",
            "Epoch 126/1000\n",
            "549/549 [==============================] - 55s 100ms/step - loss: 0.6099 - val_loss: 0.5915\n",
            "Epoch 127/1000\n",
            "549/549 [==============================] - 46s 84ms/step - loss: 0.6081 - val_loss: 0.6261\n",
            "Epoch 128/1000\n",
            "549/549 [==============================] - 44s 80ms/step - loss: 0.6008 - val_loss: 0.5917\n",
            "Epoch 129/1000\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.6105interval evaluation - epoch: 128 - explained variance: 0.406523\n",
            "549/549 [==============================] - 48s 88ms/step - loss: 0.6105 - val_loss: 0.6027\n",
            "Epoch 130/1000\n",
            "549/549 [==============================] - 57s 103ms/step - loss: 0.6155 - val_loss: 1.1389\n",
            "Epoch 131/1000\n",
            "549/549 [==============================] - 49s 89ms/step - loss: 0.6146 - val_loss: 0.5714\n",
            "Epoch 132/1000\n",
            "549/549 [==============================] - 60s 109ms/step - loss: 0.6231 - val_loss: 0.7238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = my_saluki.predict(X_val)\n",
        "print(\"Explained Var Score: %.2f\" % explained_variance_score(y_val, y_pred))\n",
        "print(\"R2 Score: %.2f\" % r2_score(y_val, y_pred))"
      ],
      "metadata": {
        "id": "7hCHlQnlWPVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecdc2e1-9596-41d4-a555-c2c71d4131c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 2s 27ms/step\n",
            "Explained Var Score: 0.43\n",
            "R2 Score: 0.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_saluki.save('my_saluki5_21.h5')"
      ],
      "metadata": {
        "id": "RDHswe1X_W34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_loss(history):\n",
        "    fig, ax = plt.subplots(figsize = (5,5))\n",
        "    ax.plot(history['loss'][1:])\n",
        "    ax.plot(history['val_loss'][1:])\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('mean squared error')"
      ],
      "metadata": {
        "id": "5_Wi1QFKWEVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history.history)"
      ],
      "metadata": {
        "id": "KDZw8D75goko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "bd7e137d-8823-469e-e84b-b5da3675afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}